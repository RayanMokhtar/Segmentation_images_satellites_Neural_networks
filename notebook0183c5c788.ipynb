{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<h1 style='color:green'>ABOUT</h1>\n",
    "\n",
    "<p style='color:lightgreen'>These last decades, Earth Observation brought quantities of new perspectives from geosciences to human activity monitoring. As more data became available, artificial intelligence techniques led to very successful results for understanding remote sensing data. Moreover, various acquisition techniques such as Synthetic Aperture Radar (SAR) can also be used for problems that could not be tackled only through optical images. This is the case for weather-related disasters such as floods or hurricanes, which are generally associated with large clouds cover. Yet, machine learning on SAR data is still considered challenging due to the lack of available labeled data. This dataset is composed of co-registered optical and SAR images time series for the detection of flood events.</p>\n",
    "\n",
    "[source](https://mlhub.earth/data/sen12floods)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<h2 style='color:green'>Dataset</h2>\n",
    "\n",
    "<p style='color:lightgreen'>The dataset is composed of 412\n",
    "time series with 4 to 20 optical images and 10 to 58 SAR im-\n",
    "ages in each sequence. On average, there are 9 optical and 14\n",
    "SAR images per sequence. The period of acquisition goes from\n",
    "December 2018 to May 2019. A flood event is occuring in 40%\n",
    "of the optical Sentinel 2 images and in 47% of the SAR Sen-\n",
    "tinel 1 images. As in the MediaEval dataset, once a flood oc-\n",
    "curred in a sequence, all the subsequent images are labeled as\n",
    "flooded which corresponds to the hypothesis that the surface\n",
    "still presents characteristic modifications after the event.</p>\n",
    "\n",
    "[source](https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B2-2020/1343/2020/isprs-archives-XLIII-B2-2020-1343-2020.pdf)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<h2 style='color:green'>Other notebooks related to this project</h2>\n",
    "\n",
    "    \n",
    "* [Data Download](https://www.kaggle.com/code/virajkadam/detecting-flood-from-satellite-img-data-download)\n",
    "    \n",
    "* [The next notebook in this series(Time Series)](https://www.kaggle.com/virajkadam/detecting-floods-time-series-prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:17:31.571947Z",
     "iopub.status.busy": "2022-09-26T11:17:31.571406Z",
     "iopub.status.idle": "2022-09-26T11:17:39.185513Z",
     "shell.execute_reply": "2022-09-26T11:17:39.184424Z",
     "shell.execute_reply.started": "2022-09-26T11:17:31.571862Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gc\n",
    "import rasterio as rio\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import  cm\n",
    "import cv2\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:17:39.190946Z",
     "iopub.status.busy": "2022-09-26T11:17:39.189801Z",
     "iopub.status.idle": "2022-09-26T11:17:39.199337Z",
     "shell.execute_reply": "2022-09-26T11:17:39.198354Z",
     "shell.execute_reply.started": "2022-09-26T11:17:39.1909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 7\n",
    "    img_size = (256,256)\n",
    "    BATCH_SIZE = 3\n",
    "    Autotune = tf.data.AUTOTUNE\n",
    "    validation_size = 0.2\n",
    "    class_dict= {0:'No Flooding', \n",
    "                 1: 'Flooding'}\n",
    "    \n",
    "    test_run = False \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Input data\n",
    "\n",
    "    Read more about the dataset here : https://clmrmb.github.io/SEN12-FLOOD/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:17:39.20534Z",
     "iopub.status.busy": "2022-09-26T11:17:39.203772Z",
     "iopub.status.idle": "2022-09-26T11:17:44.627438Z",
     "shell.execute_reply": "2022-09-26T11:17:44.626527Z",
     "shell.execute_reply.started": "2022-09-26T11:17:39.205252Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: '../input/sen12flood/sen12flood/sen12floods_s1_labels/sen12floods_s1_labels/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m s2_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../input/sen12flood/sen12flood/sen12floods_s2_labels/sen12floods_s2_labels/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m s1_check \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms1_labels\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(s1_tiles \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m file\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m     10\u001b[0m         s1_check \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: '../input/sen12flood/sen12flood/sen12floods_s1_labels/sen12floods_s1_labels/'"
     ]
    }
   ],
   "source": [
    "s1_labels = '../input/sen12flood/sen12flood/sen12floods_s1_labels/sen12floods_s1_labels/'\n",
    "s1_tiles = '../input/sen12flood/sen12flood/sen12floods_s1_source/sen12floods_s1_source/'\n",
    "\n",
    "s2_tiles = '../input/sen12flood/sen12flood/sen12floods_s2_source/sen12floods_s2_source/'\n",
    "s2_labels = '../input/sen12flood/sen12flood/sen12floods_s2_labels/sen12floods_s2_labels/'\n",
    "\n",
    "s1_check = 0\n",
    "for file in os.listdir(s1_labels):\n",
    "    if os.path.exists(s1_tiles + '/' + file.replace('labels','source')):\n",
    "        s1_check += 1\n",
    "        \n",
    "         \n",
    "assert s1_check == len(os.listdir(s1_tiles)), 'You my friend , are definintely a idiot!'\n",
    "    \n",
    "s2_check = 0\n",
    "for file in os.listdir(s2_labels):\n",
    "    if os.path.exists(s2_tiles + '/' + file.replace('labels','source')):\n",
    "        s2_check += 1\n",
    "        \n",
    "        \n",
    "assert s2_check == len(os.listdir(s2_tiles)), 'You my friend , are definintely  the idiot!'\n",
    "\n",
    "\n",
    "s1_check,s2_check "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Make a dataset of paths and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:17:44.630098Z",
     "iopub.status.busy": "2022-09-26T11:17:44.62955Z",
     "iopub.status.idle": "2022-09-26T11:17:44.637468Z",
     "shell.execute_reply": "2022-09-26T11:17:44.636754Z",
     "shell.execute_reply.started": "2022-09-26T11:17:44.630059Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    '''loads a json file'''\n",
    "    with open(path,'r') as file:\n",
    "        js = json.load(file)\n",
    "        \n",
    "    return js\n",
    "\n",
    "# collectionss1 = load_json('../input/sen12flood/sen12flood/sen12floods_s1_source/sen12floods_s1_source/collection.json')\n",
    "# collections2= load_json('../input/sen12flood/sen12flood/sen12floods_s2_source/sen12floods_s2_source/collection.json')\n",
    "# collections2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:17:44.643287Z",
     "iopub.status.busy": "2022-09-26T11:17:44.642764Z",
     "iopub.status.idle": "2022-09-26T11:17:44.682133Z",
     "shell.execute_reply": "2022-09-26T11:17:44.681405Z",
     "shell.execute_reply.started": "2022-09-26T11:17:44.64325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_label_json(label_json):\n",
    "    '''process a single label json'''\n",
    "    info_dict = {}\n",
    "    \n",
    "    info_dict['geometry'] = label_json['geometry']['coordinates']\n",
    "    info_dict['label'] = label_json['properties']['FLOODING']\n",
    "    info_dict['date'] = label_json['properties']['date']\n",
    "    info_dict['tile_number'] = label_json['properties']['tile']\n",
    "#     info_dict['full_data_coverage']= label_json['properties']['FULL-DATA-COVERAGE']\n",
    "    \n",
    "    return info_dict\n",
    "\n",
    "\n",
    "def process_label_stac(stac_json):\n",
    "    return stac_json['id']\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def image_path_from_label_dir(image_parent_dir:str,\n",
    "                              label_file :str)->str:\n",
    "    \n",
    "    return image_parent_dir + '/' + label_file.replace('labels','source')\n",
    "    \n",
    "    \n",
    "\n",
    "def process_json(label_path,image_directory):\n",
    "    '''get the data for a single example\n",
    "     Inputs \n",
    "     label_path : path to the label folder \n",
    "     image_directory: path to the corresponding image directory'''\n",
    "    \n",
    "    \n",
    "\n",
    "    #get image directory for that label\n",
    "    folder_id = label_path.rsplit('/',1)[1]\n",
    "    image_dir_path = image_path_from_label_dir(image_directory,folder_id)\n",
    "\n",
    "    if not os.path.exists(image_dir_path):\n",
    "        return {'File_not_found':image_dir_path}\n",
    "    \n",
    "    \n",
    "    for file in os.listdir(label_path):\n",
    "        #if image dir exists \n",
    "        if file.startswith('labels'):\n",
    "            label_json = load_json(os.path.join(label_path,file))\n",
    "        else:\n",
    "            stac_json = load_json(os.path.join(label_path,file))\n",
    "\n",
    "\n",
    "    #get data \n",
    "    info_dict = process_label_json(label_json)\n",
    "\n",
    "    #get id \n",
    "    info_dict['id'] = process_label_stac(stac_json)\n",
    "    \n",
    "    #location id \n",
    "    info_dict['location_id'] = info_dict['id'].split('_')[3]\n",
    "    \n",
    "    \n",
    "    info_dict['image_dir'] = image_dir_path\n",
    "    \n",
    "    \n",
    "    return info_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:17:44.684094Z",
     "iopub.status.busy": "2022-09-26T11:17:44.683534Z",
     "iopub.status.idle": "2022-09-26T11:17:44.697387Z",
     "shell.execute_reply": "2022-09-26T11:17:44.696614Z",
     "shell.execute_reply.started": "2022-09-26T11:17:44.684058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_dataframe(label_directory,image_directory):\n",
    "    '''get dataframe from the nested label directory'''\n",
    "    records = []\n",
    "    \n",
    "        \n",
    "    for folder in os.listdir(label_directory):\n",
    "        if folder.startswith('sen12'):\n",
    "#             print(folder,label_directory)\n",
    "            folder_path = label_directory + '/' + folder\n",
    "            \n",
    "            \n",
    "            #get data for a single example\n",
    "            feature = process_json(label_path=folder_path,\n",
    "                                   image_directory=image_directory)\n",
    "            \n",
    "            \n",
    "            records.append(feature)\n",
    "            \n",
    "            \n",
    "    return pd.DataFrame.from_records(data = records)\n",
    "\n",
    "\n",
    "\n",
    "def type_cast_dataset(dataset):\n",
    "    '''typecasting columns in dataset'''\n",
    "    dataset['label'] = dataset['label'].astype(int)\n",
    "    \n",
    "    dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "    dataset['tile_number'] = dataset['tile_number'].astype('int8')\n",
    "    \n",
    "    \n",
    "    return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:17:44.699232Z",
     "iopub.status.busy": "2022-09-26T11:17:44.698688Z",
     "iopub.status.idle": "2022-09-26T11:18:26.758297Z",
     "shell.execute_reply": "2022-09-26T11:18:26.757493Z",
     "shell.execute_reply.started": "2022-09-26T11:17:44.699198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "s1_data = type_cast_dataset(\n",
    "                            get_dataframe(\n",
    "                                label_directory=s1_labels,\n",
    "                                image_directory=s1_tiles\n",
    "                                        )\n",
    "                            )\n",
    "\n",
    "\n",
    "s2_data = type_cast_dataset(\n",
    "                            get_dataframe(label_directory=s2_labels,\n",
    "                                          image_directory=s2_tiles)\n",
    "                            )\n",
    "\n",
    "print(f'Number of unique locations in Sentinel1 (SAR) data : {s1_data.location_id.nunique()}')\n",
    "print(f'Number of unique locations in Sentinel2 (optical) data : {s2_data.location_id.nunique()}')\n",
    "\n",
    "s1_data.shape,s2_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:18:26.759984Z",
     "iopub.status.busy": "2022-09-26T11:18:26.759627Z",
     "iopub.status.idle": "2022-09-26T11:18:26.855362Z",
     "shell.execute_reply": "2022-09-26T11:18:26.854592Z",
     "shell.execute_reply.started": "2022-09-26T11:18:26.759949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# saving datasets\n",
    "s1_data.to_csv('s1_data.csv',index=False)\n",
    "s2_data.to_csv('s2_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:25.444543Z",
     "iopub.status.busy": "2022-09-26T11:20:25.444184Z",
     "iopub.status.idle": "2022-09-26T11:20:25.448955Z",
     "shell.execute_reply": "2022-09-26T11:20:25.448119Z",
     "shell.execute_reply.started": "2022-09-26T11:20:25.444512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_raster(filepath):\n",
    "    '''load a single band raster'''\n",
    "    with rio.open(filepath) as file: \n",
    "        raster = file.read().squeeze(axis=0)\n",
    "        \n",
    "    return raster\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Loading multiple raster bands as single raster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:26.789549Z",
     "iopub.status.busy": "2022-09-26T11:20:26.789188Z",
     "iopub.status.idle": "2022-09-26T11:20:26.803006Z",
     "shell.execute_reply": "2022-09-26T11:20:26.80203Z",
     "shell.execute_reply.started": "2022-09-26T11:20:26.789519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_s1_tiffs(folder,\n",
    "                  scaling_values=[50.,100.]):\n",
    "    images = []\n",
    "    i = 0\n",
    "    for im in sorted(os.listdir(folder)):\n",
    "         \n",
    "        if im.rsplit('.',maxsplit=1)[1] == 'tif':\n",
    "            \n",
    "            path = folder + '/' + im\n",
    "            band = load_raster(path)\n",
    "            band = band / scaling_values[i]\n",
    "            \n",
    "            band = cv2.resize(band,\n",
    "                              CFG.img_size)\n",
    "            \n",
    "            images.append(band)\n",
    "            i+=1 \n",
    "                    \n",
    "    return np.dstack(images)\n",
    "\n",
    "\n",
    "def load_s2_tiffs(folder,\n",
    "                  scaling_value=10000.):\n",
    "    images = []\n",
    "    for im in sorted(os.listdir(folder)):\n",
    "        if im.rsplit('.',maxsplit=1)[1] == 'tif':    \n",
    "            path = folder + '/' + im\n",
    "            band = load_raster(path)\n",
    "            band = band/ scaling_value\n",
    "            \n",
    "            band = cv2.resize(band,CFG.img_size)\n",
    "            images.append(band)   \n",
    "\n",
    "    return np.dstack(images)\n",
    "                    \n",
    "def load_rgb_tiffs(folder,\n",
    "                  scaling_value=10000.):\n",
    "    '''load R,G and B bands'''\n",
    "    \n",
    "    images = []\n",
    "    for im in sorted(os.listdir(folder)):\n",
    "        name,file_format = im.rsplit('.',maxsplit=1)\n",
    "        if ((file_format== 'tif') and (name in ['B02','B03','B04'])):    \n",
    "            path = folder + '/' + im\n",
    "            band = load_raster(path)\n",
    "            band = band/ scaling_value\n",
    "            \n",
    "            band = cv2.resize(band,CFG.img_size)\n",
    "            images.append(band)   \n",
    "\n",
    "    return np.dstack(images)[:,:,::-1]\n",
    "\n",
    "\n",
    "    \n",
    "def tf_load_s1(path):    \n",
    "    path = path.numpy().decode('utf-8')\n",
    "    return load_s1_tiffs(path)\n",
    "    \n",
    "    \n",
    "\n",
    "def tf_load_s2(path):    \n",
    "    path = path.numpy().decode('utf-8')\n",
    "    return load_s2_tiffs(path)\n",
    "\n",
    "\n",
    "def tf_load_rgb(path):    \n",
    "    path = path.numpy().decode('utf-8')\n",
    "    return load_rgb_tiffs(path)\n",
    "    \n",
    "def process_image_s1(filename):\n",
    "    '''function for preprocessing in tensorflow data'''\n",
    "    \n",
    "    return tf.py_function(tf_load_s1, \n",
    "                          [filename], \n",
    "                          tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "def process_image_s2(filename):\n",
    "    '''function for preprocessing in tensorflow data'''\n",
    "    \n",
    "    return tf.py_function(tf_load_s2, \n",
    "                          [filename], \n",
    "                          tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "def process_image_rgb(filename):\n",
    "    '''function for preprocessing in tensorflow data'''\n",
    "    \n",
    "    return tf.py_function(tf_load_rgb, \n",
    "                          [filename], \n",
    "                          tf.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:26.921047Z",
     "iopub.status.busy": "2022-09-26T11:20:26.920456Z",
     "iopub.status.idle": "2022-09-26T11:20:28.00142Z",
     "shell.execute_reply": "2022-09-26T11:20:28.000621Z",
     "shell.execute_reply.started": "2022-09-26T11:20:26.921018Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def count_rasters_in_folder(path):\n",
    "    count = 0 \n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        if file.rsplit('.',1)[1] == 'tif':\n",
    "            count +=1 \n",
    "            \n",
    "    return count \n",
    "    \n",
    "    \n",
    "s2_data['raster_count'] = s2_data.image_dir.apply(lambda x : count_rasters_in_folder(x))\n",
    "\n",
    "#value counts \n",
    "s2_data['raster_count'].value_counts()\n",
    "\n",
    "\n",
    "s2_data=s2_data[s2_data['raster_count']==12] # take only valid rasters\n",
    "# s2_data[s2_data['raster_count']==0]['location_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Visualize some images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "**lets take a look at some optical RGB images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:28.003605Z",
     "iopub.status.busy": "2022-09-26T11:20:28.002952Z",
     "iopub.status.idle": "2022-09-26T11:20:29.04393Z",
     "shell.execute_reply": "2022-09-26T11:20:29.042448Z",
     "shell.execute_reply.started": "2022-09-26T11:20:28.003551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "chk = load_s2_tiffs(s2_data.query('label==1')['image_dir'].values[11])\n",
    "plt.imshow(chk[:,:,1:4][:,:,::-1])\n",
    "plt.title('Flooding')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "chk = load_s2_tiffs(s2_data.query('label==0')['image_dir'].values[20])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(chk[:,:,1:4][:,:,::-1])\n",
    "plt.title('No Flooding')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:31.104243Z",
     "iopub.status.busy": "2022-09-26T11:20:31.103854Z",
     "iopub.status.idle": "2022-09-26T11:20:31.78512Z",
     "shell.execute_reply": "2022-09-26T11:20:31.781896Z",
     "shell.execute_reply.started": "2022-09-26T11:20:31.10421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "chk = load_s2_tiffs(s2_data.query('label==1')['image_dir'].values[101])\n",
    "plt.imshow(chk[:,:,1:4][:,:,::-1])\n",
    "plt.title('Flooding')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "chk = load_s2_tiffs(s2_data.query('label==0')['image_dir'].values[11])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(chk[:,:,1:4][:,:,::-1])\n",
    "plt.title('No Flooding')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Some SAR images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:34.677069Z",
     "iopub.status.busy": "2022-09-26T11:20:34.676701Z",
     "iopub.status.idle": "2022-09-26T11:20:35.314161Z",
     "shell.execute_reply": "2022-09-26T11:20:35.313475Z",
     "shell.execute_reply.started": "2022-09-26T11:20:34.677039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "plt.suptitle('SAR images (VH)')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "\n",
    "chk = load_s1_tiffs(s1_data.query('label==1')['image_dir'].values[11])\n",
    "plt.imshow(chk[:,:,1])\n",
    "plt.title('Flooding')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "chk = load_s2_tiffs(s2_data.query('label==0')['image_dir'].values[11])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(chk[:,:,1])\n",
    "plt.title('No Flooding')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:35.316316Z",
     "iopub.status.busy": "2022-09-26T11:20:35.315489Z",
     "iopub.status.idle": "2022-09-26T11:20:35.834857Z",
     "shell.execute_reply": "2022-09-26T11:20:35.834083Z",
     "shell.execute_reply.started": "2022-09-26T11:20:35.316281Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,8))\n",
    "plt.suptitle('SAR images (VV)')\n",
    "\n",
    "\n",
    "r_idx = np.random.randint(low=0,high=500)\n",
    "plt.subplot(1,2,1)\n",
    "chk = load_s1_tiffs(s1_data.query('label==1')['image_dir'].values[r_idx])\n",
    "plt.imshow(chk[:,:,0])\n",
    "plt.title('Flooding')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "chk = load_s2_tiffs(s2_data.query('label==0')['image_dir'].values[r_idx])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(chk[:,:,0])\n",
    "plt.title('No Flooding')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:35.837108Z",
     "iopub.status.busy": "2022-09-26T11:20:35.83656Z",
     "iopub.status.idle": "2022-09-26T11:20:36.550042Z",
     "shell.execute_reply": "2022-09-26T11:20:36.549348Z",
     "shell.execute_reply.started": "2022-09-26T11:20:35.837069Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,8))\n",
    "plt.suptitle('SAR images (VV)')\n",
    "\n",
    "\n",
    "r_idx = np.random.randint(low=0,high=500)\n",
    "plt.subplot(1,2,1)\n",
    "chk = load_s1_tiffs(s1_data.query('label==1')['image_dir'].values[r_idx])\n",
    "plt.imshow(chk[:,:,0])\n",
    "plt.title('Flooding')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "chk = load_s2_tiffs(s2_data.query('label==0')['image_dir'].values[r_idx])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(chk[:,:,0])\n",
    "plt.title('No Flooding')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Lets look at the distribution of target values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:38.183059Z",
     "iopub.status.busy": "2022-09-26T11:20:38.182366Z",
     "iopub.status.idle": "2022-09-26T11:20:38.445155Z",
     "shell.execute_reply": "2022-09-26T11:20:38.444411Z",
     "shell.execute_reply.started": "2022-09-26T11:20:38.183021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(s1_data.label)\n",
    "plt.title('Sentinel -1 target distribution')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(s2_data.label)\n",
    "plt.title('Sentinel - 2 target distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Making a TF dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "    First lets split the dataset into training and validation set. We will stratify based on location id to ensure that locations are well represented in traininng and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:39.135045Z",
     "iopub.status.busy": "2022-09-26T11:20:39.134677Z",
     "iopub.status.idle": "2022-09-26T11:20:39.150722Z",
     "shell.execute_reply": "2022-09-26T11:20:39.149907Z",
     "shell.execute_reply.started": "2022-09-26T11:20:39.135013Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#isolating single loaction ids (as they will be a problem for stratification)\n",
    "\n",
    "# single example locations \n",
    "single_index = s2_data['location_id'].value_counts()[s2_data['location_id'].value_counts()==1].index\n",
    "\n",
    "single_index_df = s2_data[s2_data['location_id'].isin(single_index)].reset_index(drop=True)\n",
    "s2_data0 = s2_data[~(s2_data['location_id'].isin(single_index))].reset_index(drop=True)\n",
    "\n",
    "s2_data0.shape,single_index_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Split dataset into train and validation splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:39.958183Z",
     "iopub.status.busy": "2022-09-26T11:20:39.957736Z",
     "iopub.status.idle": "2022-09-26T11:20:40.250023Z",
     "shell.execute_reply": "2022-09-26T11:20:40.247659Z",
     "shell.execute_reply.started": "2022-09-26T11:20:39.958142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#traintest split \n",
    "\n",
    "s1_data_tr,s1_data_val= train_test_split(s1_data,\n",
    "                                          test_size = CFG.validation_size,\n",
    "                                          random_state = CFG.seed,\n",
    "                                          stratify = s1_data.location_id)\n",
    "\n",
    "\n",
    "\n",
    "s2_data_tr,s2_data_val = train_test_split(s2_data0,\n",
    "                                          test_size = CFG.validation_size,\n",
    "                                          random_state = CFG.seed,\n",
    "                                          stratify =  s2_data0.location_id)\n",
    "\n",
    "s2_data_tr = s2_data_tr.append(single_index_df,ignore_index=True)\n",
    "\n",
    "del s2_data0;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:41.042803Z",
     "iopub.status.busy": "2022-09-26T11:20:41.042192Z",
     "iopub.status.idle": "2022-09-26T11:20:41.05281Z",
     "shell.execute_reply": "2022-09-26T11:20:41.051772Z",
     "shell.execute_reply.started": "2022-09-26T11:20:41.042766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "s1_data_tr.label.value_counts(1),s1_data_val.label.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:41.184518Z",
     "iopub.status.busy": "2022-09-26T11:20:41.184185Z",
     "iopub.status.idle": "2022-09-26T11:20:41.194118Z",
     "shell.execute_reply": "2022-09-26T11:20:41.19315Z",
     "shell.execute_reply.started": "2022-09-26T11:20:41.184489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "s2_data_tr.label.value_counts(1),s2_data_val.label.value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Function for image augmentations**\n",
    "\n",
    "    Although the Augmentations are simple, we cannot use them on SAR images , as even simple operations like flipping can change the meaning of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:49.334259Z",
     "iopub.status.busy": "2022-09-26T11:20:49.333889Z",
     "iopub.status.idle": "2022-09-26T11:20:49.341871Z",
     "shell.execute_reply": "2022-09-26T11:20:49.340804Z",
     "shell.execute_reply.started": "2022-09-26T11:20:49.334227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def augment_image_multispectral(image):\n",
    "    '''perform simple image augmentations'''\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_crop(image, size=(*CFG.img_size,12))\n",
    "    \n",
    "    rot = tf.random.normal((1,),mean = 0.35, stddev=0.15)\n",
    "    \n",
    "    if rot > 0.5:\n",
    "        image = tf.image.rot90(image)\n",
    "\n",
    "    return image \n",
    "\n",
    "def augment_image(image):\n",
    "    '''perform simple image augmentations'''\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_crop(image, size=(*CFG.img_size,3))\n",
    "    \n",
    "    rot = tf.random.normal((1,),mean = 0.35, stddev=0.15)\n",
    "    \n",
    "    if rot > 0.5:\n",
    "        image = tf.image.rot90(image)\n",
    "\n",
    "    return image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:50.67682Z",
     "iopub.status.busy": "2022-09-26T11:20:50.675989Z",
     "iopub.status.idle": "2022-09-26T11:20:50.685098Z",
     "shell.execute_reply": "2022-09-26T11:20:50.68435Z",
     "shell.execute_reply.started": "2022-09-26T11:20:50.676786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_tf_dataset(image_paths,\n",
    "                   labels=None, # put none for test data set\n",
    "                   image_processing_fn=None,\n",
    "                   augment_fn = None\n",
    "                  ):\n",
    "    \n",
    "    '''returns a tf dataset object\n",
    "    Inputs: \n",
    "    image_paths : paths to images\n",
    "    labels: labels of each image\n",
    "    image_processing_fn:  function to load and preprocess images \n",
    "    augment_fn : function to augment images '''\n",
    "    \n",
    "    #seperate datasets\n",
    "    if labels is not None:\n",
    "        labels_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    #load images \n",
    "    image_dataset = image_dataset.map(image_processing_fn,\n",
    "                                      num_parallel_calls=tf.data.AUTOTUNE)\n",
    "     \n",
    "    if augment_fn is not None:\n",
    "        \n",
    "        image_dataset = image_dataset.map(augment_fn,\n",
    "                                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "     \n",
    "    \n",
    "    if labels is not None:\n",
    "        return tf.data.Dataset.zip((image_dataset,labels_dataset))\n",
    "    \n",
    "    \n",
    "    return image_dataset\n",
    "\n",
    "\n",
    "\n",
    "def optimize_pipeline(tf_dataset,\n",
    "                      batch_size = CFG.BATCH_SIZE,\n",
    "                      Autotune_fn = CFG.Autotune,\n",
    "                      cache= False,\n",
    "                      batch = True):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # prefetch(load the data with cpu,while gpu is training) the data in memory \n",
    "    tf_dataset = tf_dataset.prefetch(buffer_size=Autotune_fn)  \n",
    "    if cache:\n",
    "        tf_dataset = tf_dataset.cache()                        # store data in RAM  \n",
    "        \n",
    "    tf_dataset =  tf_dataset.shuffle(buffer_size=50)         # shuffle \n",
    "    \n",
    "    if batch:\n",
    "        tf_dataset = tf_dataset.batch(batch_size)              #split the data in batches  \n",
    "    \n",
    "    return tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Making dataset pipelines with TF data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:51.710133Z",
     "iopub.status.busy": "2022-09-26T11:20:51.709776Z",
     "iopub.status.idle": "2022-09-26T11:20:54.658028Z",
     "shell.execute_reply": "2022-09-26T11:20:54.657145Z",
     "shell.execute_reply.started": "2022-09-26T11:20:51.710102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Sentinel 1 dataset (not using augmentation here)\n",
    "\n",
    "S1_dataset_tr = optimize_pipeline(tf_dataset=get_tf_dataset(image_paths = s1_data_tr.image_dir.values,\n",
    "                                               labels = s1_data_tr.label,\n",
    "                                               image_processing_fn = process_image_s1),\n",
    "                                  \n",
    "                                  batch_size = 3 * CFG.BATCH_SIZE)\n",
    "\n",
    "\n",
    "S1_dataset_val = optimize_pipeline(tf_dataset = get_tf_dataset(image_paths = s1_data_val.image_dir.values,\n",
    "                                                           labels = s1_data_val.label,\n",
    "                                                           image_processing_fn = process_image_s1 ),\n",
    "                                   batch_size = 3* CFG.BATCH_SIZE\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:55.828238Z",
     "iopub.status.busy": "2022-09-26T11:20:55.827872Z",
     "iopub.status.idle": "2022-09-26T11:20:56.203608Z",
     "shell.execute_reply": "2022-09-26T11:20:56.202775Z",
     "shell.execute_reply.started": "2022-09-26T11:20:55.828207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#sentinel 2 dataset \n",
    "S2_dataset_tr = optimize_pipeline(get_tf_dataset(image_paths = s2_data_tr.image_dir.values,\n",
    "                                                   labels = s2_data_tr.label,\n",
    "                                                   image_processing_fn = process_image_s2,\n",
    "                                                   augment_fn = augment_image_multispectral)\n",
    "                                 )\n",
    "\n",
    "\n",
    "S2_dataset_val = optimize_pipeline(get_tf_dataset(image_paths = s2_data_val.image_dir.values,\n",
    "                                                   labels = s2_data_val.label,\n",
    "                                                   image_processing_fn = process_image_s2,\n",
    "                                                   augment_fn = augment_image_multispectral)\n",
    "                                  )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:20:56.587354Z",
     "iopub.status.busy": "2022-09-26T11:20:56.586846Z",
     "iopub.status.idle": "2022-09-26T11:20:56.957337Z",
     "shell.execute_reply": "2022-09-26T11:20:56.956546Z",
     "shell.execute_reply.started": "2022-09-26T11:20:56.587319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "RGB_dataset_tr = optimize_pipeline(get_tf_dataset(image_paths = s2_data_tr.image_dir.values,\n",
    "                                                   labels = s2_data_tr.label,\n",
    "                                                   image_processing_fn = process_image_rgb,\n",
    "                                                   augment_fn = augment_image),\n",
    "                                   batch_size = 3* CFG.BATCH_SIZE\n",
    "                                 )\n",
    "\n",
    "\n",
    "RGB_dataset_val = optimize_pipeline(get_tf_dataset(image_paths = s2_data_val.image_dir.values,\n",
    "                                                   labels = s2_data_val.label,\n",
    "                                                   image_processing_fn = process_image_rgb,\n",
    "                                                   augment_fn = augment_image),\n",
    "                                    batch_size = 3* CFG.BATCH_SIZE\n",
    "                                  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Checking the values of pixels in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.status.busy": "2022-09-26T11:18:35.414711Z",
     "iopub.status.idle": "2022-09-26T11:18:35.415401Z",
     "shell.execute_reply": "2022-09-26T11:18:35.415197Z",
     "shell.execute_reply.started": "2022-09-26T11:18:35.415172Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# max_vals_vv = []\n",
    "# mean_vals_vv =[]\n",
    "\n",
    "\n",
    "# max_vals_vh = []\n",
    "# mean_vals_vh =[]\n",
    "\n",
    "# for x,y in S1_dataset_tr.as_numpy_iterator():\n",
    "#     # vv band \n",
    "#     max_vals_vv.append(x[:,:,:,0].max()); mean_vals_vv.append(x[:,:,:,0].mean())\n",
    "    \n",
    "#     # vh band \n",
    "#     max_vals_vh.append(x[:,:,:,1].max()); mean_vals_vh.append(x[:,:,:,1].mean())\n",
    "    \n",
    "# # band 1value distributions \n",
    "# plt.figure(figsize=(16,10))\n",
    "\n",
    "# sns.distplot(max_vals_vv,label = 'VV band Max values',color='b')\n",
    "# # sns.distplot(mean_vals_vv,label = 'VV band Mean values',color = 'g')\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.title('VV band values Distribution')\n",
    "# plt.show()\n",
    "\n",
    "# # band 1value distributions \n",
    "# plt.figure(figsize=(16,10))\n",
    "\n",
    "# sns.distplot(max_vals_vh,label = 'VH band Max values',color='b')\n",
    "# # sns.distplot(mean_vals_vh,label = 'VH band Mean values',color = 'g')\n",
    "\n",
    "\n",
    "# plt.title('VH band values Distribution')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Checking to see if the Pipelines work as expected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:21:03.786771Z",
     "iopub.status.busy": "2022-09-26T11:21:03.786345Z",
     "iopub.status.idle": "2022-09-26T11:21:05.336129Z",
     "shell.execute_reply": "2022-09-26T11:21:05.335191Z",
     "shell.execute_reply.started": "2022-09-26T11:21:03.786734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for x,y in S1_dataset_tr.take(1): # take one batch for checking \n",
    "    print(f'shape of SAR dataset input {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:21:05.338245Z",
     "iopub.status.busy": "2022-09-26T11:21:05.337856Z",
     "iopub.status.idle": "2022-09-26T11:21:09.84121Z",
     "shell.execute_reply": "2022-09-26T11:21:09.839157Z",
     "shell.execute_reply.started": "2022-09-26T11:21:05.338204Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for x,y in S2_dataset_tr.take(1): # take one batch for checking \n",
    "    print(f'shape of MultiSpectral dataset input {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:21:09.844893Z",
     "iopub.status.busy": "2022-09-26T11:21:09.844502Z",
     "iopub.status.idle": "2022-09-26T11:21:11.083431Z",
     "shell.execute_reply": "2022-09-26T11:21:11.082676Z",
     "shell.execute_reply.started": "2022-09-26T11:21:09.844863Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for x,y in RGB_dataset_tr.take(1): # take one batch for checking \n",
    "    print(f'shape of MultiSpectral dataset input {x.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "#  CNN Models\n",
    "    CNN models to identify flooding in opotical and SAR images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:21:17.585362Z",
     "iopub.status.busy": "2022-09-26T11:21:17.584995Z",
     "iopub.status.idle": "2022-09-26T11:21:17.604232Z",
     "shell.execute_reply": "2022-09-26T11:21:17.602103Z",
     "shell.execute_reply.started": "2022-09-26T11:21:17.585328Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def multichannel_cnn(num_channels:int,\n",
    "                     hidden_units:int, #number of  hidden dense \n",
    "                     weights = None  # none for random init, use imagenet for imagenet weights \n",
    "                    ):\n",
    "    '''model that takes multiple channel as input, instead of using the rgb channels as by default'''\n",
    "    \n",
    "    \n",
    "    backbone = tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "                                            include_top=False,\n",
    "                                            input_shape = (*CFG.img_size,num_channels),\n",
    "                                            weights=weights,\n",
    "                                            pooling = 'avg')\n",
    "    \n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(backbone.output)\n",
    "    x = tf.keras.layers.Dense(hidden_units,\n",
    "                              activation = 'relu')(x)\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    final_out = tf.keras.layers.Dense(2,\n",
    "                                      activation = 'softmax')(x)\n",
    "    \n",
    "    \n",
    "    #make a model \n",
    "    model = tf.keras.Model(inputs = backbone.input, \n",
    "                  outputs = final_out)\n",
    "    \n",
    "    return model \n",
    "\n",
    "\n",
    "# plot train and val acc as  a function of epochs\n",
    "def plot_history(history,addn_metric=None):\n",
    "    '''\n",
    "    Inputs\n",
    "    history:history object from tensorflow\n",
    "    add_metric: metric name in the history (like f1_score)'''\n",
    "    his=pd.DataFrame(history.history)\n",
    "    \n",
    "    if addn_metric:\n",
    "        plt.subplots(1,3,figsize=(20,6))\n",
    "        \n",
    "        #loss:\n",
    "        ax1=plt.subplot(1,3,1)\n",
    "        ax1.plot(range(len(his)),his['loss'],color='g',label='training')\n",
    "        ax1.plot(range(len(his)),his['val_loss'],color='r',label='validation')\n",
    "        ax1.set_xlabel('EPOCHS')\n",
    "        ax1.set_ylabel('LOSS')\n",
    "        ax1.legend()\n",
    "        ax1.set_title('Loss Per Epoch')\n",
    "\n",
    "        #accuracy\n",
    "        ax2=plt.subplot(1,3,2)\n",
    "        ax2.plot(range(len(his)),his['accuracy'],color='g',label='training_acc')\n",
    "        ax2.plot(range(len(his)),his['val_accuracy'],color='r',label='validation_acc')\n",
    "        ax2.set_xlabel('EPOCHS')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.legend()\n",
    "        ax2.set_title('Accuracy Per Epoch')\n",
    "\n",
    "    \n",
    "        \n",
    "        ax3= plt.subplot(1,3,3)\n",
    "        ax3.plot(range(len(his)),his[f'{addn_metric}'],color='g',label='training')\n",
    "        ax3.plot(range(len(his)),his[f'val_{addn_metric}'],color='r',label='validation')\n",
    "        ax3.set_xlabel('EPOCHS')\n",
    "        ax3.set_ylabel(f'{addn_metric}')\n",
    "        ax3.legend()\n",
    "        ax3.set_title(f'{addn_metric} Per Epoch')\n",
    "\n",
    "        \n",
    "    else:\n",
    "        plt.subplots(1,2,figsize=(20,8))\n",
    "        \n",
    "    \n",
    "    \n",
    "        #loss:\n",
    "        ax1=plt.subplot(1,2,1)\n",
    "        ax1.plot(range(len(his)),his['loss'],color='g',label='training')\n",
    "        ax1.plot(range(len(his)),his['val_loss'],color='r',label='validation')\n",
    "        ax1.set_xlabel('EPOCHS')\n",
    "        ax1.set_ylabel('LOSS')\n",
    "        ax1.legend()\n",
    "        ax1.set_title('Loss Per Epoch')\n",
    "\n",
    "        #accuracy\n",
    "        ax2=plt.subplot(1,2,2)\n",
    "        ax2.plot(range(len(his)),his['accuracy'],color='g',label='training_acc')\n",
    "        ax2.plot(range(len(his)),his['val_accuracy'],color='r',label='validation_acc')\n",
    "        ax2.set_xlabel('EPOCHS')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.legend()\n",
    "        ax2.set_title('Accuracy Per Epoch')\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:21:19.20648Z",
     "iopub.status.busy": "2022-09-26T11:21:19.206112Z",
     "iopub.status.idle": "2022-09-26T11:21:19.213861Z",
     "shell.execute_reply": "2022-09-26T11:21:19.212908Z",
     "shell.execute_reply.started": "2022-09-26T11:21:19.206449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#from https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Building and training the SAR CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:21:22.263567Z",
     "iopub.status.busy": "2022-09-26T11:21:22.263209Z",
     "iopub.status.idle": "2022-09-26T11:21:24.105606Z",
     "shell.execute_reply": "2022-09-26T11:21:24.104257Z",
     "shell.execute_reply.started": "2022-09-26T11:21:22.263536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SAR_CNN = multichannel_cnn(num_channels = 2,\n",
    "                           hidden_units = 512, #number of  hidden dense \n",
    "                          )\n",
    "\n",
    "\n",
    "\n",
    "SAR_CNN.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss = 'sparse_categorical_crossentropy',\n",
    "                metrics = ['accuracy',f1_score,recall_m,precision_m]\n",
    "               )\n",
    "\n",
    "#check on some data \n",
    "# SAR_CNN(x)\n",
    "\n",
    "\n",
    "\n",
    "!mkdir CNN_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Defining callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:21:25.560948Z",
     "iopub.status.busy": "2022-09-26T11:21:25.560504Z",
     "iopub.status.idle": "2022-09-26T11:21:25.570248Z",
     "shell.execute_reply": "2022-09-26T11:21:25.568987Z",
     "shell.execute_reply.started": "2022-09-26T11:21:25.560912Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 2 if CFG.test_run else 75\n",
    "# callbacks \n",
    "#reduce_learning rate\n",
    "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(patience=3,\n",
    "                                                factor=0.75,\n",
    "                                                min_delta=1e-2,\n",
    "                                                monitor='val_accuracy',\n",
    "                                                verbose=1,\n",
    "                                                mode='max')\n",
    "\n",
    "#early stopping \n",
    "early_stopping=tf.keras.callbacks.EarlyStopping(patience=15,\n",
    "                                              min_delta=1e-3,\n",
    "                                              monitor='val_accuracy',\n",
    "                                              restore_best_weights=True,\n",
    "                                              mode='max')\n",
    "\n",
    "\n",
    "# exponential decay \n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    '''learning rate scheduler, decays expo after the tenth epoch'''\n",
    "\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "\n",
    "    \n",
    "learning_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "\n",
    "callbacks_1= [reduce_lr,early_stopping,learning_scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Training on SAR data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T11:21:33.585117Z",
     "iopub.status.busy": "2022-09-26T11:21:33.584743Z",
     "iopub.status.idle": "2022-09-26T11:55:12.4072Z",
     "shell.execute_reply": "2022-09-26T11:55:12.406424Z",
     "shell.execute_reply.started": "2022-09-26T11:21:33.585085Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hist1 = SAR_CNN.fit(S1_dataset_tr,\n",
    "                    validation_data = S1_dataset_val,\n",
    "                    epochs = EPOCHS,\n",
    "                    callbacks = callbacks_1\n",
    "                   )\n",
    "\n",
    "\n",
    "#save model\n",
    "sar_model_path = 'CNN_models/SAR_CNN.h5'\n",
    "SAR_CNN.save(filepath = 'CNN_models/SAR_CNN.h5')\n",
    "\n",
    "\n",
    "#plot history \n",
    "plot_history(hist1,'f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "****Evaluate on validation dataset****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T12:02:01.484252Z",
     "iopub.status.busy": "2022-09-26T12:02:01.483411Z",
     "iopub.status.idle": "2022-09-26T12:02:08.769167Z",
     "shell.execute_reply": "2022-09-26T12:02:08.768221Z",
     "shell.execute_reply.started": "2022-09-26T12:02:01.484213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SAR_CNN.evaluate(S1_dataset_val)\n",
    "\n",
    "del SAR_CNN;gc.collect()\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Model explainablity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "    Saliency and Grad Cam. Lets look at what the model is looking at while making htat decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T12:02:15.313825Z",
     "iopub.status.busy": "2022-09-26T12:02:15.312955Z",
     "iopub.status.idle": "2022-09-26T12:02:27.266161Z",
     "shell.execute_reply": "2022-09-26T12:02:27.265201Z",
     "shell.execute_reply.started": "2022-09-26T12:02:15.313788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install tf_keras_vis -q\n",
    "import tf_keras_vis \n",
    "\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus\n",
    "\n",
    "\n",
    "tf_keras_vis.__version__\n",
    "\n",
    "\n",
    "def model_modifier_function(cloned_model):\n",
    "    '''modify model activation'''\n",
    "    cloned_model.layers[-1].activation = tf.keras.activations.linear\n",
    "\n",
    "    \n",
    "def get_saliency(img,\n",
    "                 score,\n",
    "                 cnn_model,\n",
    "                 model_modifier=model_modifier_function):\n",
    "    #saliency map\n",
    "    \n",
    "\n",
    "    # Create Saliency object.\n",
    "    saliency = Saliency(cnn_model,\n",
    "                        model_modifier=model_modifier_function,\n",
    "                        clone=True)\n",
    "    #saliency map \n",
    "    sal_map  = saliency(score,\n",
    "                        img,\n",
    "                        smooth_samples=20, # The number of calculating gradients iterations.\n",
    "                        smooth_noise=0.20) # noise spread level.\n",
    "    return sal_map\n",
    "\n",
    "def get_gradcam(img,\n",
    "                score,\n",
    "                cnn_model,\n",
    "                model_modifier=model_modifier_function):\n",
    "\n",
    "    # Create Gradcam object\n",
    "    gradcam = Gradcam(cnn_model,\n",
    "                      model_modifier,\n",
    "                      clone=True)\n",
    "\n",
    "    # Generate heatmap with GradCAM\n",
    "    cam = gradcam(score,\n",
    "                  img,\n",
    "                  seek_penultimate_conv_layer=True)\n",
    "    \n",
    "    heatmap = np.uint8(cm.jet(cam[0])[..., :3] * 255)\n",
    "    \n",
    "    \n",
    "    return heatmap\n",
    "\n",
    "def get_gradcam_plus(img,\n",
    "                    score,\n",
    "                    model,\n",
    "                    model_modifier=ReplaceToLinear()):\n",
    "    \n",
    "    # Create GradCAM++ object\n",
    "    gradcam = GradcamPlusPlus(model,\n",
    "                          model_modifier=model_modifier,\n",
    "                          clone=True)\n",
    "    \n",
    "    cam = gradcam(score,\n",
    "                  img)\n",
    "    \n",
    "    heatmap = np.uint8(cm.jet(cam[0])[..., :3] * 255)\n",
    "    \n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T12:02:27.268686Z",
     "iopub.status.busy": "2022-09-26T12:02:27.268354Z",
     "iopub.status.idle": "2022-09-26T12:02:28.502804Z",
     "shell.execute_reply": "2022-09-26T12:02:28.501629Z",
     "shell.execute_reply.started": "2022-09-26T12:02:27.268648Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SAR_CNN = tf.keras.models.load_model('CNN_models/SAR_CNN.h5',\n",
    "                                     custom_objects={'f1_score':f1_score,\n",
    "                                                     'recall_m':recall_m,\n",
    "                                                     'precision_m':precision_m}\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T12:02:29.561223Z",
     "iopub.status.busy": "2022-09-26T12:02:29.560739Z",
     "iopub.status.idle": "2022-09-26T12:02:58.372441Z",
     "shell.execute_reply": "2022-09-26T12:02:58.371448Z",
     "shell.execute_reply.started": "2022-09-26T12:02:29.56119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.subplots(4,4,figsize=(8*3,8*3))\n",
    "n = 4\n",
    "idx= 1\n",
    "\n",
    "\n",
    "for images,labels in S1_dataset_val.shuffle(buffer_size=5).take(1):\n",
    "    print(images.shape,labels.shape)\n",
    "\n",
    "    for i in range(4):\n",
    "        #get label \n",
    "        img = images[i]\n",
    "        lab = int(labels[i].numpy())\n",
    "        \n",
    "        #predict on image\n",
    "        pred = np.argmax(SAR_CNN.predict(img[tf.newaxis,:,:,:]))\n",
    "        prd = int(pred.ravel())\n",
    "\n",
    "        score1 = CategoricalScore(lab)\n",
    "\n",
    "        plt.subplot(4,4,idx)\n",
    "        plt.title(f'orignal image ({CFG.class_dict[lab]})')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img[:,:,0])\n",
    "        idx+=1\n",
    "\n",
    "        #saliency\n",
    "\n",
    "        plt.subplot(4,4,idx)\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]} (saliency map)')\n",
    "        sal = get_saliency(img,\n",
    "                           score1,\n",
    "                           cnn_model = SAR_CNN).squeeze(axis=0)\n",
    "        \n",
    "#         print(sal.shape)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img[:,:,0])\n",
    "        plt.imshow(sal,alpha=0.25,cmap='jet') #overlay\n",
    "        idx+=1\n",
    "\n",
    "        #gradcam\n",
    "        plt.subplot(4,4,idx)\n",
    "        gdcam = get_gradcam(img,\n",
    "                            score1,\n",
    "                           cnn_model = SAR_CNN)\n",
    "        plt.imshow(img[:,:,0])\n",
    "        plt.imshow(gdcam,alpha=0.30,cmap='jet') #overlay\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(gradcam)')\n",
    "        plt.axis('off')\n",
    "        idx+=1\n",
    "\n",
    "\n",
    "        #gradcam ++\n",
    "        plt.subplot(4,4,idx)\n",
    "        gdcam_pls = get_gradcam_plus(img,\n",
    "                                     score1,\n",
    "                                     model = SAR_CNN)\n",
    "        plt.imshow(img[:,:,0])\n",
    "        plt.imshow(gdcam_pls,alpha=0.30,cmap='jet') #overlay\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(gradcam + +)')\n",
    "        plt.axis('off')\n",
    "        idx+=1\n",
    "\n",
    "        if idx>16:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T12:02:58.374717Z",
     "iopub.status.busy": "2022-09-26T12:02:58.374269Z",
     "iopub.status.idle": "2022-09-26T12:03:26.310651Z",
     "shell.execute_reply": "2022-09-26T12:03:26.309648Z",
     "shell.execute_reply.started": "2022-09-26T12:02:58.374681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.subplots(4,4,figsize=(8*3,8*3))\n",
    "n = 4\n",
    "idx= 1\n",
    "\n",
    "for images,labels in S1_dataset_val.shuffle(buffer_size=5).take(1):\n",
    "    print(images.shape,labels.shape)\n",
    "\n",
    "    for i in range(4):\n",
    "        #get label \n",
    "        img = images[i]\n",
    "        lab = int(labels[i].numpy())\n",
    "     \n",
    "        #predict on image\n",
    "        pred = np.argmax(SAR_CNN.predict(img[tf.newaxis,:,:,:]))\n",
    "        score1 = CategoricalScore(lab)\n",
    "        prd = int(pred.ravel())\n",
    "\n",
    "        plt.subplot(4,4,idx)\n",
    "        plt.title(f'orignal image ({CFG.class_dict[lab]})')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img[:,:,1])\n",
    "        idx+=1\n",
    "        #saliency\n",
    "        plt.subplot(4,4,idx)\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]} (saliency map)')\n",
    "        sal = get_saliency(img,\n",
    "                           score1,\n",
    "                           cnn_model = SAR_CNN).squeeze(axis=0)\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.imshow(img[:,:,1])\n",
    "        plt.imshow(sal,alpha=0.25,cmap='jet') #overlay\n",
    "        idx+=1\n",
    "\n",
    "        #gradcam\n",
    "        plt.subplot(4,4,idx)\n",
    "        gdcam = get_gradcam(img,\n",
    "                            score1,\n",
    "                           cnn_model = SAR_CNN)\n",
    "        plt.imshow(img[:,:,1])\n",
    "        plt.imshow(gdcam,alpha=0.30,cmap='jet') #overlay\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(gradcam)')\n",
    "        plt.axis('off')\n",
    "        idx+=1\n",
    "\n",
    "\n",
    "        #gradcam ++\n",
    "        plt.subplot(4,4,idx)\n",
    "        gdcam_pls = get_gradcam_plus(img,\n",
    "                                     score1,\n",
    "                                     model = SAR_CNN)\n",
    "        plt.imshow(img[:,:,1])\n",
    "        plt.imshow(gdcam_pls,alpha=0.30,cmap='jet') #overlay\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(gradcam + +)')\n",
    "        plt.axis('off')\n",
    "        idx+=1\n",
    "\n",
    "        if idx>16:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T12:03:26.313767Z",
     "iopub.status.busy": "2022-09-26T12:03:26.313193Z",
     "iopub.status.idle": "2022-09-26T12:03:26.680021Z",
     "shell.execute_reply": "2022-09-26T12:03:26.679224Z",
     "shell.execute_reply.started": "2022-09-26T12:03:26.31373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#delete \n",
    "del SAR_CNN;S1_dataset_val;S1_dataset_tr;gc.collect()\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Building and training the RGB - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T12:06:47.115896Z",
     "iopub.status.busy": "2022-09-26T12:06:47.115283Z",
     "iopub.status.idle": "2022-09-26T12:06:48.907061Z",
     "shell.execute_reply": "2022-09-26T12:06:48.906234Z",
     "shell.execute_reply.started": "2022-09-26T12:06:47.115851Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "RGB_CNN = multichannel_cnn(num_channels = 3,\n",
    "                           hidden_units = 512, #number of  hidden dense\n",
    "                           weights = 'imagenet'\n",
    "                          )\n",
    "\n",
    "\n",
    "RGB_CNN.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss = 'sparse_categorical_crossentropy',\n",
    "                metrics = ['accuracy',f1_score,recall_m,precision_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-09-26T12:06:51.782747Z",
     "iopub.status.busy": "2022-09-26T12:06:51.782268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hist2 = RGB_CNN.fit(RGB_dataset_tr,\n",
    "                    validation_data = RGB_dataset_val,\n",
    "                    epochs = EPOCHS,\n",
    "                    callbacks = callbacks_1)\n",
    "\n",
    "#save model\n",
    "\n",
    "RGB_CNN.save(filepath = 'CNN_models/RGB_CNN.h5')\n",
    "\n",
    "plot_history(hist2,'f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Checking the GradCAM and saliency Maps for RGB CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.status.busy": "2022-09-26T11:18:35.447909Z",
     "iopub.status.idle": "2022-09-26T11:18:35.44864Z",
     "shell.execute_reply": "2022-09-26T11:18:35.448374Z",
     "shell.execute_reply.started": "2022-09-26T11:18:35.448349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.subplots(4,4,figsize=(8*3,8*3))\n",
    "n = 4\n",
    "idx= 1\n",
    "\n",
    "\n",
    "for images,labels in RGB_dataset_val.shuffle(buffer_size=12).take(1):\n",
    "\n",
    "    for i in range(4):\n",
    "        #get label \n",
    "        img = images[i]\n",
    "        lab = int(labels[i].numpy())\n",
    "\n",
    "\n",
    "#         print(img.shape,lab.shape)\n",
    "        score1 = CategoricalScore(lab)\n",
    "\n",
    "\n",
    "\n",
    "        #predict on image\n",
    "        prd= np.argmax(RGB_CNN.predict(img[tf.newaxis,:,:,:]))\n",
    "\n",
    "\n",
    "        plt.subplot(4,4,idx)\n",
    "        plt.title(f'orignal image ({CFG.class_dict[lab]})')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        idx+=1\n",
    "\n",
    "        #saliency\n",
    "\n",
    "        plt.subplot(4,4,idx)\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(saliency map)')\n",
    "        sal = get_saliency(img,\n",
    "                           score1,\n",
    "                           cnn_model = RGB_CNN).squeeze(axis=0)\n",
    "        \n",
    "#         print(sal.shape)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        plt.imshow(sal,alpha=0.45,cmap='jet') #overlay\n",
    "        idx+=1\n",
    "\n",
    "        #gradcam\n",
    "        plt.subplot(4,4,idx)\n",
    "        gdcam = get_gradcam(img,\n",
    "                            score1,\n",
    "                           cnn_model = RGB_CNN)\n",
    "        plt.imshow(img)\n",
    "        plt.imshow(gdcam,alpha=0.30,cmap='jet') #overlay\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(gradcam)')\n",
    "        plt.axis('off')\n",
    "        idx+=1\n",
    "\n",
    "\n",
    "        #gradcam ++\n",
    "        plt.subplot(4,4,idx)\n",
    "        gdcam_pls = get_gradcam_plus(img,\n",
    "                                     score1,\n",
    "                                     model = RGB_CNN)\n",
    "        plt.imshow(img)\n",
    "        plt.imshow(gdcam_pls,alpha=0.30,cmap='jet') #overlay\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(gradcam + +)')\n",
    "        plt.axis('off')\n",
    "        idx+=1\n",
    "\n",
    "        if idx>16:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.status.busy": "2022-09-26T11:18:35.449816Z",
     "iopub.status.idle": "2022-09-26T11:18:35.45048Z",
     "shell.execute_reply": "2022-09-26T11:18:35.450276Z",
     "shell.execute_reply.started": "2022-09-26T11:18:35.450252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.subplots(4,4,figsize=(8*3,8*3))\n",
    "n = 4\n",
    "idx= 1\n",
    "\n",
    "\n",
    "for images,labels in RGB_dataset_val.shuffle(buffer_size=12).take(1):\n",
    "\n",
    "    for i in range(4):\n",
    "        #get label \n",
    "        img = images[i]\n",
    "        lab = int(labels[i].numpy())\n",
    "\n",
    "\n",
    "#         print(img.shape,lab.shape)\n",
    "        score1 = CategoricalScore(lab)\n",
    "\n",
    "\n",
    "\n",
    "        #predict on image\n",
    "        prd= np.argmax(RGB_CNN.predict(img[tf.newaxis,:,:,:]))\n",
    "\n",
    "\n",
    "        plt.subplot(4,4,idx)\n",
    "        plt.title(f'orignal image ({CFG.class_dict[lab]})')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        idx+=1\n",
    "\n",
    "        #saliency\n",
    "\n",
    "        plt.subplot(4,4,idx)\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(saliency map)')\n",
    "        sal = get_saliency(img,\n",
    "                           score1,\n",
    "                           cnn_model = RGB_CNN).squeeze(axis=0)\n",
    "        \n",
    "#         print(sal.shape)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        plt.imshow(sal,alpha=0.45,cmap='jet') #overlay\n",
    "        idx+=1\n",
    "\n",
    "        #gradcam\n",
    "        plt.subplot(4,4,idx)\n",
    "        gdcam = get_gradcam(img,\n",
    "                            score1,\n",
    "                           cnn_model = RGB_CNN)\n",
    "        plt.imshow(img)\n",
    "        plt.imshow(gdcam,alpha=0.30,cmap='jet') #overlay\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(gradcam)')\n",
    "        plt.axis('off')\n",
    "        idx+=1\n",
    "\n",
    "\n",
    "        #gradcam ++\n",
    "        plt.subplot(4,4,idx)\n",
    "        gdcam_pls = get_gradcam_plus(img,\n",
    "                                     score1,\n",
    "                                     model = RGB_CNN)\n",
    "        plt.imshow(img)\n",
    "        plt.imshow(gdcam_pls,alpha=0.30,cmap='jet') #overlay\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(gradcam + +)')\n",
    "        plt.axis('off')\n",
    "        idx+=1\n",
    "\n",
    "        if idx>16:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.status.busy": "2022-09-26T11:18:35.451633Z",
     "iopub.status.idle": "2022-09-26T11:18:35.452291Z",
     "shell.execute_reply": "2022-09-26T11:18:35.452074Z",
     "shell.execute_reply.started": "2022-09-26T11:18:35.452051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#delete \n",
    "del RGB_CNN;gc.collect()\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Building and training the Multispectral - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.status.busy": "2022-09-26T11:18:35.453538Z",
     "iopub.status.idle": "2022-09-26T11:18:35.454256Z",
     "shell.execute_reply": "2022-09-26T11:18:35.454027Z",
     "shell.execute_reply.started": "2022-09-26T11:18:35.454002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "multispectral_CNN = multichannel_cnn(num_channels = 12,\n",
    "                                    hidden_units = 512, #number of  hidden dense \n",
    "                                    )\n",
    "\n",
    "\n",
    "#check on some data \n",
    "# multispectral_CNN(x)\n",
    "\n",
    "\n",
    "multispectral_CNN.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001,momentum = 0.0),\n",
    "                loss = 'sparse_categorical_crossentropy',\n",
    "                metrics = ['accuracy',f1_score,recall_m,precision_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "editable": false,
    "execution": {
     "iopub.status.busy": "2022-09-26T11:18:35.455455Z",
     "iopub.status.idle": "2022-09-26T11:18:35.456181Z",
     "shell.execute_reply": "2022-09-26T11:18:35.455953Z",
     "shell.execute_reply.started": "2022-09-26T11:18:35.455927Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hist2 = multispectral_CNN.fit(S2_dataset_tr,\n",
    "                    validation_data = S2_dataset_val,\n",
    "                    epochs = EPOCHS,\n",
    "                    callbacks = callbacks_1)\n",
    "\n",
    "#save model\n",
    "\n",
    "multispectral_CNN.save(filepath = 'CNN_models/S2_CNN.h5')\n",
    "\n",
    "plot_history(hist2,'f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Checking the decision mechanism for Multispectral model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.status.busy": "2022-09-26T11:18:35.457484Z",
     "iopub.status.idle": "2022-09-26T11:18:35.458198Z",
     "shell.execute_reply": "2022-09-26T11:18:35.457971Z",
     "shell.execute_reply.started": "2022-09-26T11:18:35.457945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.subplots(4,4,figsize=(8*3,8*3))\n",
    "n = 4\n",
    "idx= 1\n",
    "\n",
    "\n",
    "for images,labels in S2_dataset_val.shuffle(buffer_size=12).take(1):\n",
    "    print(images.shape,labels.shape)\n",
    "\n",
    "    for i in range(4):\n",
    "        #get label \n",
    "        img = images[i]\n",
    "        lab = int(labels[i].numpy())\n",
    "\n",
    "\n",
    "#         print(img.shape,lab.shape)\n",
    "        score1 = CategoricalScore(lab)\n",
    "\n",
    "\n",
    "\n",
    "        #predict on image\n",
    "        prd= np.argmax(multispectral_CNN.predict(img[tf.newaxis,:,:,:]))\n",
    "\n",
    "\n",
    "        plt.subplot(4,4,idx)\n",
    "        plt.title(f'orignal image ({CFG.class_dict[lab]})')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img[:,:,1:4][:,:,::-1])\n",
    "        idx+=1\n",
    "\n",
    "        #saliency\n",
    "\n",
    "        plt.subplot(4,4,idx)\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(saliency map)')\n",
    "        sal = get_saliency(img,\n",
    "                           score1,\n",
    "                           cnn_model = multispectral_CNN).squeeze(axis=0)\n",
    "        \n",
    "#         print(sal.shape)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img[:,:,1:4][:,:,::-1])\n",
    "        plt.imshow(sal,alpha=0.45,cmap='jet') #overlay\n",
    "        idx+=1\n",
    "\n",
    "        #gradcam\n",
    "        plt.subplot(4,4,idx)\n",
    "        gdcam = get_gradcam(img,\n",
    "                            score1,\n",
    "                           cnn_model = multispectral_CNN)\n",
    "        plt.imshow(img[:,:,1:4][:,:,::-1])\n",
    "        plt.imshow(gdcam,alpha=0.30,cmap='jet') #overlay\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(gradcam)')\n",
    "        plt.axis('off')\n",
    "        idx+=1\n",
    "\n",
    "\n",
    "        #gradcam ++\n",
    "        plt.subplot(4,4,idx)\n",
    "        gdcam_pls = get_gradcam_plus(img,\n",
    "                                     score1,\n",
    "                                     model = multispectral_CNN)\n",
    "        plt.imshow(img[:,:,1:4][:,:,::-1])\n",
    "        plt.imshow(gdcam_pls,alpha=0.30,cmap='jet') #overlay\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(gradcam + +)')\n",
    "        plt.axis('off')\n",
    "        idx+=1\n",
    "\n",
    "        if idx>16:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false,
    "execution": {
     "iopub.status.busy": "2022-09-26T11:18:35.459419Z",
     "iopub.status.idle": "2022-09-26T11:18:35.460084Z",
     "shell.execute_reply": "2022-09-26T11:18:35.45988Z",
     "shell.execute_reply.started": "2022-09-26T11:18:35.459856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.subplots(4,4,figsize=(8*3,8*3))\n",
    "n = 4\n",
    "idx= 1\n",
    "\n",
    "\n",
    "for images,labels in S2_dataset_val.shuffle(buffer_size=12).take(1):\n",
    "    print(images.shape,labels.shape)\n",
    "\n",
    "    for i in range(4):\n",
    "        #get label \n",
    "        img = images[i]\n",
    "        lab = int(labels[i].numpy())\n",
    "\n",
    "\n",
    "#         print(img.shape,lab.shape)\n",
    "        score1 = CategoricalScore(lab)\n",
    "\n",
    "\n",
    "\n",
    "        #predict on image\n",
    "        prd= np.argmax(multispectral_CNN.predict(img[tf.newaxis,:,:,:]))\n",
    "\n",
    "\n",
    "        plt.subplot(4,4,idx)\n",
    "        plt.title(f'orignal image ({CFG.class_dict[lab]})')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img[:,:,1:4][:,:,::-1])\n",
    "        idx+=1\n",
    "\n",
    "        #saliency\n",
    "\n",
    "        plt.subplot(4,4,idx)\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(saliency map)')\n",
    "        sal = get_saliency(img,\n",
    "                           score1,\n",
    "                           cnn_model = multispectral_CNN).squeeze(axis=0)\n",
    "        \n",
    "#         print(sal.shape)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img[:,:,1:4][:,:,::-1])\n",
    "        plt.imshow(sal,alpha=0.30,cmap='jet') #overlay\n",
    "        idx+=1\n",
    "\n",
    "        #gradcam\n",
    "        plt.subplot(4,4,idx)\n",
    "        gdcam = get_gradcam(img,\n",
    "                            score1,\n",
    "                           cnn_model = multispectral_CNN)\n",
    "        plt.imshow(img[:,:,1:4][:,:,::-1])\n",
    "        plt.imshow(gdcam,alpha=0.30,cmap='jet') #overlay\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(gradcam)')\n",
    "        plt.axis('off')\n",
    "        idx+=1\n",
    "\n",
    "\n",
    "        #gradcam ++\n",
    "        plt.subplot(4,4,idx)\n",
    "        gdcam_pls = get_gradcam_plus(img,\n",
    "                                     score1,\n",
    "                                     model = multispectral_CNN)\n",
    "        plt.imshow(img[:,:,1:4][:,:,::-1])\n",
    "        plt.imshow(gdcam_pls,alpha=0.30,cmap='jet') #overlay\n",
    "        plt.title(f'predicted {CFG.class_dict[prd]}(gradcam + +)')\n",
    "        plt.axis('off')\n",
    "        idx+=1\n",
    "\n",
    "        if idx>16:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Model for temporal forecasting\n",
    "\n",
    "    This notebooks covered the prediction of flooding using satellite images. But this dataset is as time series dataset, which has multiple images of locations before and during the flood. So we will try to cover the temporal aspect of predicting flooding in the next notebook. This can be especially important in some cases where there are water bodies in the image, and hence there needs to be additional signal to distinguish cases of flooding ffrom normal conditions\n",
    "    \n",
    "[The temporal forecasting notebook can be found here](https://www.kaggle.com/code/virajkadam/detecting-floods-time-series-prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# References and resources \n",
    "\n",
    "* https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B2-2020/1343/2020/isprs-archives-XLIII-B2-2020-1343-2020.pdf\n",
    "* https://arxiv.org/pdf/2006.10027v1.pdf#page=2"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2227758,
     "sourceId": 3725387,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30197,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
