{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332     1\n",
      "448     1\n",
      "474     1\n",
      "942     1\n",
      "1105    1\n",
      "1286    1\n",
      "1770    1\n",
      "1825    1\n",
      "2345    1\n",
      "2411    1\n",
      "Name: chemin_directory, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"satellite_S1_enrichi_part.csv\", dtype={\"chemin_directory\": str})\n",
    "print(df[df[\"chemin_directory\"] == \"1\"][\"chemin_directory\"].head(10))#remettre le fichier csv avec ce format\n",
    "df.to_csv(\"satellite_S1_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      id chemin_directory\n",
      "0  sen12floods_s1_labels_0165_2019_02_06            '0165\n",
      "1  sen12floods_s1_labels_0026_2018_12_19            '0026\n",
      "2  sen12floods_s1_labels_0100_2018_12_17            '0100\n",
      "3  sen12floods_s1_labels_0305_2019_02_11            '0305\n",
      "4  sen12floods_s1_labels_0246_2019_04_06            '0246\n",
      "5  sen12floods_s1_labels_0272_2019_03_09            '0272\n",
      "6  sen12floods_s1_labels_0214_2019_02_28            '0214\n",
      "7  sen12floods_s1_labels_0321_2019_03_07            '0321\n",
      "8  sen12floods_s1_labels_0143_2019_02_06            '0143\n",
      "9  sen12floods_s1_labels_0320_2019_02_23            '0320\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def extract_directory_from_id(label_info):\n",
    "    \"\"\"\n",
    "    Extrait le chiffre après 'labels_' dans une chaîne de caractères.\n",
    "    Préserve les zéros non significatifs.\n",
    "    \n",
    "    Exemples:\n",
    "      'sen12floods_s1_labels_0026_2018_12_19' -> '0026'\n",
    "      'sen12floods_s1_labels_26_2019_01_23'  -> '26'\n",
    "    \"\"\"\n",
    "    if pd.isna(label_info):  # Gestion des valeurs NaN\n",
    "        return None\n",
    "        \n",
    "    match = re.search(r'labels_(\\d+)', str(label_info))\n",
    "    if match:\n",
    "        return match.group(1)  # Retourne les chiffres extraits en tant que chaîne\n",
    "    return None\n",
    "\n",
    "# Application de la fonction à la colonne 'id'\n",
    "df[\"chemin_directory\"] = df[\"id\"].apply(extract_directory_from_id)\n",
    "df[\"chemin_directory\"] = df[\"chemin_directory\"].apply(lambda x: f\"'{x}\" if pd.notna(x) else x)\n",
    "\n",
    "# Afficher quelques résultats pour vérification\n",
    "print(df[[\"id\", \"chemin_directory\"]].head(10))\n",
    "df.to_csv(\"satellite_S1_new.csv\", index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0026'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_directory_from_id(\"sen12floods_s1_labels_0026_2018_12_19\")  # Doit retourner '0026'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"propriétés des images \n",
    "Géoréférencement : Système de projection, coordonnées, résolution\n",
    "Spécifications des bandes : Plage de longueurs d’onde, sensibilité, numéros de bandes\n",
    "Angles solaires : Zenith et azimut, utiles pour corriger l’éclairage\n",
    "\n",
    "Bandes : VV (vertical-vertical) et VH (vertical-horizontal)\n",
    "Résolution : ~10 m\n",
    "Avantage : Pénètre les nuages, top pour surveiller les inondations\n",
    "Sentinel-2 (Optique multispectrale)\n",
    "\n",
    "Format : GeoTIFF\n",
    "Bandes : 12 bandes (certaines à 10 m, d’autres à 20 m voire 60 m)\n",
    "\n",
    "NDVI = (Bande NIR – Bande Rouge) / (Bande NIR + Bande Rouge)\n",
    "\n",
    "Pourquoi NDVI ? : Il te donne une indication sur la vitalité de la végétation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(csv_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess the metadata CSV file\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['date']):\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "    #nettoyage du nouveau_chemin comme présent dans le fichier csv actuelleemnt , les \n",
    "    df['nouveau_chemin'] = df['nouveau_chemin'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "    \n",
    "    #\"dans nouveau chemin , on peut recréer le chemin de l'image , avec la polarisation manière plus précise\"\n",
    "    df['vh_path'] = df['nouveau_chemin'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None)\n",
    "    df['vv_path'] = df['nouveau_chemin'].apply(lambda x: x[1] if isinstance(x, list) and len(x) > 1 else None)\n",
    "    \n",
    "    print(f\"Loaded {len(df)} samples with {df['label'].sum()} flood images\")\n",
    "    print(f\"Class distribution: {df['label'].value_counts(normalize=True).to_dict()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the dataset\n",
    "data_df = load_metadata('satellite_s1_refontes.csv')\n",
    "\n",
    "# Preview data\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARFloodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for loading SAR (Sentinel-1) flood detection data\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, img_size=(256, 256), transform=None, test_mode=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: Pandas dataframe containing image paths and labels\n",
    "            img_size: Target size for resizing images\n",
    "            transform: Optional transformations to apply\n",
    "            test_mode: If True, return image paths along with data\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        self.test_mode = test_mode\n",
    "        \n",
    "        # Check if all paths exist\n",
    "        self._validate_paths()\n",
    "        \n",
    "    def _validate_paths(self):\n",
    "        \"\"\"Validate if image paths exist\"\"\"\n",
    "        valid_indices = []\n",
    "        for idx, row in tqdm(self.dataframe.iterrows(), desc=\"Validating paths\", total=len(self.dataframe)):\n",
    "            if os.path.exists(row['vh_path']) and os.path.exists(row['vv_path']):\n",
    "                valid_indices.append(idx)\n",
    "        \n",
    "        print(f\"Valid paths: {len(valid_indices)}/{len(self.dataframe)}\")\n",
    "        self.dataframe = self.dataframe.loc[valid_indices].reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Load and return a sample from the dataset\n",
    "        \"\"\"\n",
    "        # Get image paths and label\n",
    "        vh_path = self.dataframe.iloc[idx]['vh_path']\n",
    "        vv_path = self.dataframe.iloc[idx]['vv_path']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "        \n",
    "        # Load SAR images (VH and VV channels)\n",
    "        vh_image = self._load_raster(vh_path, scaling_value=50.0)  # Different scaling for VH\n",
    "        vv_image = self._load_raster(vv_path, scaling_value=100.0)  # Different scaling for VV\n",
    "        \n",
    "        # Stack channels to create a 2-channel image\n",
    "        image = np.stack([vh_image, vv_image], axis=0)  # Shape: (2, H, W)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        image = torch.from_numpy(image).float()\n",
    "        \n",
    "        # Apply transformations if specified\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Return image path for testing/visualization if in test mode\n",
    "        if self.test_mode:\n",
    "            return image, label, {'vh_path': vh_path, 'vv_path': vv_path}\n",
    "        \n",
    "        return image, label\n",
    "        \n",
    "    def _load_raster(self, filepath, scaling_value=1.0):\n",
    "        \"\"\"\n",
    "        Load a single band raster file and preprocess it\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to the raster file\n",
    "            scaling_value: Value to scale the data by\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed raster data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with rasterio.open(filepath) as src:\n",
    "                # Read the raster data and squeeze to remove singleton dimensions\n",
    "                band = src.read(1)\n",
    "                \n",
    "                # Apply scaling\n",
    "                band = band / scaling_value\n",
    "                \n",
    "                # Clip values to prevent outliers\n",
    "                band = np.clip(band, 0, 5)\n",
    "                \n",
    "                # Resize to target size\n",
    "                band = cv2.resize(band, self.img_size)\n",
    "                \n",
    "                return band\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filepath}: {e}\")\n",
    "            # Return a zero array if loading fails\n",
    "            return np.zeros(self.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(dataframe, img_size=(256, 256), batch_size=32, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the data and create DataLoaders for training and validation\n",
    "    \"\"\"\n",
    "    # Split data into train and validation sets\n",
    "    train_df, val_df = train_test_split(\n",
    "        dataframe, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state,\n",
    "        stratify=dataframe['label']  # Ensure class balance in both sets\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set: {len(train_df)} samples\")\n",
    "    print(f\"Validation set: {len(val_df)} samples\")\n",
    "    \n",
    "    # Define transformations for training and validation\n",
    "    # For SAR data, we need to be careful with augmentations\n",
    "    # Certain transformations like horizontal/vertical flips can change the physical meaning\n",
    "    train_transform = transforms.Compose([\n",
    "        # RandomCrop can be safe for SAR data\n",
    "        transforms.RandomCrop(size=img_size, padding=int(img_size[0]*0.1)),\n",
    "        # Subtle rotation (small angles)\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        # Normalize the data - values determined empirically from your dataset\n",
    "        transforms.Normalize(mean=[0.5, 0.5], std=[0.5, 0.5])  # For 2-channel data\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        # Only normalize for validation\n",
    "        transforms.Normalize(mean=[0.5, 0.5], std=[0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = SARFloodDataset(train_df, img_size=img_size, transform=train_transform)\n",
    "    val_dataset = SARFloodDataset(val_df, img_size=img_size, transform=val_transform)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    data_df,\n",
    "    img_size=(256, 256),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sar_images(dataloader, num_samples=3):\n",
    "    \"\"\"\n",
    "    Visualize SAR images from the dataloader\n",
    "    \"\"\"\n",
    "    # Get a batch of data\n",
    "    images, labels = next(iter(dataloader))\n",
    "    \n",
    "    # Select random samples\n",
    "    indices = np.random.choice(range(len(images)), num_samples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(10, 5*num_samples))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        img = images[idx].numpy()  # Convert to numpy\n",
    "        label = labels[idx].item()  # Get the label\n",
    "        \n",
    "        # VH channel\n",
    "        axes[i, 0].imshow(img[0], cmap='gray')\n",
    "        axes[i, 0].set_title(f\"VH Channel - {'Flood' if label==1 else 'No Flood'}\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # VV channel\n",
    "        axes[i, 1].imshow(img[1], cmap='gray')\n",
    "        axes[i, 1].set_title(f\"VV Channel - {'Flood' if label==1 else 'No Flood'}\")\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some samples\n",
    "visualize_sar_images(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARFloodNet(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN for SAR-based flood detection with 2 input channels (VH, VV)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SARFloodNet, self).__init__()\n",
    "        \n",
    "        # Input: 2 channels (VH and VV polarization)\n",
    "        self.features = nn.Sequential(\n",
    "            # First conv block\n",
    "            # Input: 2×256×256, Output: 64×128×128\n",
    "            nn.Conv2d(2, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Second conv block\n",
    "            # Input: 64×128×128, Output: 128×64×64\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Third conv block\n",
    "            # Input: 128×64×64, Output: 256×32×32\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Fourth conv block\n",
    "            # Input: 256×32×32, Output: 512×16×16\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Fifth conv block\n",
    "            # Input: 512×16×16, Output: 512×8×8\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Adaptive pooling to handle variable input sizes\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Fully connected layers for classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),  # Regularization\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply convolutional feature extraction\n",
    "        x = self.features(x)\n",
    "        \n",
    "        # Apply adaptive pooling\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        # Flatten for fully connected layers\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Apply classifier\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = SARFloodNet(num_classes=2)\n",
    "print(model)\n",
    "\n",
    "# Count the number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Number of trainable parameters: {count_parameters(model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=20, learning_rate=0.001, \n",
    "                device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Train the model and validate\n",
    "    \"\"\"\n",
    "    print(f\"Training on {device}\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    # Using CrossEntropyLoss for multi-class classification\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, 'min', patience=3, factor=0.5, verbose=True\n",
    "    )\n",
    "    \n",
    "    # For tracking best performance\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1_score': []\n",
    "    }\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "        for images, labels in train_progress:\n",
    "            # Move tensors to device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track statistics\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_progress.set_postfix({'loss': loss.item(), 'acc': train_correct/train_total})\n",
    "        \n",
    "        # Calculate epoch statistics\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        # For metrics\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_progress = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "            for images, labels in val_progress:\n",
    "                # Move tensors to device\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Track statistics\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Store predictions and labels for metrics\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                # Update progress bar\n",
    "                val_progress.set_postfix({'loss': loss.item(), 'acc': val_correct/val_total})\n",
    "        \n",
    "        # Calculate epoch statistics\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Calculate metrics\n",
    "        precision = precision_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Print epoch statistics\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(\"Saved new best model!\")\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['precision'].append(precision)\n",
    "        history['recall'].append(recall)\n",
    "        history['f1_score'].append(f1)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Train the model\n",
    "trained_model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=20,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(trained_model.state_dict(), 'sar_flood_detection_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training history\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot loss\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 0].set_title('Loss')\n",
    "    axes[0, 0].set_xlabel('Epochs')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    axes[0, 1].plot(history['train_acc'], label='Train Accuracy')\n",
    "    axes[0, 1].plot(history['val_acc'], label='Validation Accuracy')\n",
    "    axes[0, 1].set_title('Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epochs')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Plot precision and recall\n",
    "    axes[1, 0].plot(history['precision'], label='Precision')\n",
    "    axes[1, 0].plot(history['recall'], label='Recall')\n",
    "    axes[1, 0].set_title('Precision and Recall')\n",
    "    axes[1, 0].set_xlabel('Epochs')\n",
    "    axes[1, 0].set_ylabel('Score')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Plot F1 score\n",
    "    axes[1, 1].plot(history['f1_score'], label='F1 Score')\n",
    "    axes[1, 1].set_title('F1 Score')\n",
    "    axes[1, 1].set_xlabel('Epochs')\n",
    "    axes[1, 1].set_ylabel('Score')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "\n",
    "def predict_flood(model, image_vh_path, image_vv_path, img_size=(256, 256), \n",
    "                 device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Make a prediction on a single SAR image\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Load the image\n",
    "    vh_image = load_and_preprocess_sar(image_vh_path, scaling_value=50.0, img_size=img_size)\n",
    "    vv_image = load_and_preprocess_sar(image_vv_path, scaling_value=100.0, img_size=img_size)\n",
    "    \n",
    "    # Stack channels\n",
    "    image = np.stack([vh_image, vv_image], axis=0)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    image = torch.from_numpy(image).float().unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Normalize\n",
    "    image = transforms.Normalize(mean=[0.5, 0.5], std=[0.5, 0.5])(image)\n",
    "    \n",
    "    # Move to device\n",
    "    image = image.to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        flood_probability = probabilities[0, 1].item()  # Probability of class 1 (flood)\n",
    "    \n",
    "    return {\n",
    "        'predicted_class': predicted_class,  # 0: No Flood, 1: Flood\n",
    "        'flood_probability': flood_probability,\n",
    "        'prediction': 'Flood' if predicted_class == 1 else 'No Flood'\n",
    "    }\n",
    "\n",
    "def load_and_preprocess_sar(filepath, scaling_value=1.0, img_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Load and preprocess a single SAR image\n",
    "    \"\"\"\n",
    "    with rasterio.open(filepath) as src:\n",
    "        band = src.read(1)\n",
    "        \n",
    "        # Apply scaling\n",
    "        band = band / scaling_value\n",
    "        \n",
    "        # Clip values\n",
    "        band = np.clip(band, 0, 5)\n",
    "        \n",
    "        # Resize\n",
    "        band = cv2.resize(band, img_size)\n",
    "        \n",
    "        return band\n",
    "\n",
    "# Example of making a prediction\n",
    "def visualize_prediction(model, test_loader, num_samples=3, \n",
    "                        device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Visualize model predictions on random test samples\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of data\n",
    "    dataiter = iter(test_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    \n",
    "    # Select random samples\n",
    "    indices = np.random.choice(range(len(images)), num_samples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, 4*num_samples))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        img = images[idx].unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "        label = labels[idx].item()\n",
    "        \n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = model(img)\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "            flood_probability = probabilities[0, 1].item()\n",
    "        \n",
    "        # Plot VH channel\n",
    "        axes[i, 0].imshow(images[idx][0].numpy(), cmap='gray')\n",
    "        axes[i, 0].set_title(f\"VH Channel - True: {'Flood' if label==1 else 'No Flood'}\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Plot VV channel\n",
    "        axes[i, 1].imshow(images[idx][1].numpy(), cmap='gray')\n",
    "        title = f\"VV Channel - Pred: {'Flood' if predicted_class==1 else 'No Flood'} ({flood_probability:.2f})\"\n",
    "        axes[i, 1].set_title(title, color='green' if predicted_class == label else 'red')\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create a test loader (if you have separate test data)\n",
    "# For demonstration, we'll use the validation loader\n",
    "test_loader = val_loader\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = evaluate_model(trained_model, test_loader)\n",
    "\n",
    "# Visualize some predictions\n",
    "visualize_prediction(trained_model, test_loader, num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
