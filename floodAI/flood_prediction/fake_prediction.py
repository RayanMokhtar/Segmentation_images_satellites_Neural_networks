import json
from skimage.transform import resize
import matplotlib.pyplot as plt
import torch
from datetime import datetime
import numpy as np
import cv2
import os
import redis
import hashlib
import traceback
from .services import get_image_satellitaire , get_bbox_from_long_lat
from .configuration import CLIENT_ID , CLIENT_SECRET
from .artificial_intelligence import FloodDetectionCNN , preprocess_sar_image_in_memory
from .cache import FloodPredictionCache
from .fake_prediction import FloodPredictionCache
import torch
import numpy as np
import rasterio
from rasterio.transform import from_bounds
from datetime import datetime
import os
from django.conf import settings
from .unet.build_sequence_unet import coordonnees_vers_tenseur , obtenir_precipitation_historique 
    

MODEL_PATH = "C:/Users/mokht/Desktop/PDS/flood_dataset/resultats/best_model.pth"


SEUIL_FAIBLE=20
SEUIL_MOYEN=50
SEUIL_ELEV√â=70
CACHE = FloodPredictionCache()

def load_model(model_path):
    """
    Charge un mod√®le PyTorch depuis le chemin sp√©cifi√©
    
    Args:
        model_path (str): Chemin vers le fichier de poids du mod√®le (.pth)
        
    Returns:
        torch.nn.Module: Le mod√®le charg√© en mode √©valuation
    """
    try:

        model_path = MODEL_PATH
        model = FloodDetectionCNN(
            num_classes=2,      # Inond√© ou non inond√©
            input_channels=2,   # VH et VV (2 canaux)
            dropout_rate=0.5
        )
        
        # 2. Charger les poids du mod√®le (state_dict)
        state_dict = torch.load(model_path, map_location=torch.device('cpu'))
        
        # 3. Appliquer les poids au mod√®le
        model.load_state_dict(state_dict)
        
        # 4. Mettre en mode √©valuation
        model.eval()
        
        print(f"Mod√®le charg√© avec succ√®s depuis {model_path}")
        return model
        
    except Exception as e:
        print(f"Erreur lors du chargement du mod√®le: {str(e)}")
        traceback.print_exc()
        raise


def predict_flood(longitude, latitude, size_km=5, start_date="2025-01-30", end_date="2025-02-07"):
    """
    Fonction simplifi√©e pour pr√©dire les inondations √† partir de coordonn√©es
    """
    try:
        print(f"Analyse de la zone: {longitude}, {latitude} (rayon {size_km}km)")
        
        cached_prediction = CACHE.get_prediction(longitude, latitude, size_km, start_date, end_date)
        if cached_prediction:
            print("Utilisation du r√©sultat en cache")
            return cached_prediction
        
        print("üîÑ Aucune donn√©e en cache, traitement en cours...")
        results_dir = "resultats_image"
        os.makedirs(results_dir, exist_ok=True)

        # 1. R√©cup√©rer les coordonn√©es de la bbox
        bbox_coords = get_bbox_from_long_lat(longitude, latitude, size_km)
        print(f"Coordonn√©es bbox: {bbox_coords}")
        
        # 2. R√©cup√©rer l'image satellitaire
        save_path = f"flood_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.tiff"
        print(f"R√©cup√©ration de l'image satellitaire...")
        
        image = get_image_satellitaire(
            CLIENT_ID, CLIENT_SECRET,
            bbox_coords=bbox_coords,
            start_date=start_date,
            end_date=end_date,
            orbit_direction="DESCENDING",
            resolution=10,
            is_visualised=False,
            save_path=save_path
        )
        if image is None or np.isnan(image).any():
            print("‚ö†Ô∏è Image non disponible ou contenant des valeurs NaN")
            return {
                'success': False, 
                'error': "Pas d'image disponible pour cette zone ou cette p√©riode"
            }
        
        # 3. Pr√©traiter l'image pour le mod√®le
        print("Pr√©traitement de l'image...")
        image_tensor = preprocess_sar_image_in_memory(
            image, 
            output_dir="flood_prediction/temp",
            visualize=False
        )
        
        # V√©rifier que le tenseur existe
        if image_tensor is None:
            raise ValueError("Le pr√©traitement de l'image a √©chou√© - image_tensor est None")
        
        print(f"Forme du tenseur d'image: {image_tensor.shape}")
        
        # Extraire VV et VH - CORRIG√â pour le format [canaux, hauteur, largeur]
        vv_band = image_tensor[0, :, :].numpy()  # Premier canal (VV)
        vh_band = image_tensor[1, :, :].numpy()  # Second canal (VH)
        # Ajouter la dimension batch
        image_tensor = image_tensor.unsqueeze(0)
        
        model_path = MODEL_PATH
        
        # 4. Charger le mod√®le
        print(f"Chargement du mod√®le: {model_path}")
        model = load_model(model_path)
    
        # 5. Faire la pr√©diction
        print("Pr√©diction en cours...")
        model.eval()  # Mode √©valuation
        
        with torch.no_grad():
            outputs = model(image_tensor)
            # Convertir en probabilit√©s avec sigmoid
            flood_probability = torch.sigmoid(outputs[:, 1]).item()

            # Obtenir la classe pr√©dite (0=non inond√©, 1=inond√©)
            _, predicted = torch.max(outputs, 1)
            
            # Calculer les m√©triques
            flood_class = predicted.item()  # 0 ou 1 pour toute l'image
            flood_percentage = flood_probability * 100  # Probabilit√© d'inondation
            confidence = max(flood_probability, 1 - flood_probability) * 100  # Confiance (0-100%)



        # 6. Cr√©er une visualisation
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = os.path.join(results_dir, f"flood_prediction_{timestamp}.png")
        
        plt.figure(figsize=(12, 12))
        
        # Visualiser l'image VV originale
        plt.subplot(2, 1, 1)
        plt.imshow(vv_band, cmap='gray')
        plt.title("Image SAR originale (VV)")
        plt.colorbar()
        plt.axis('off')
        
        # CORRECTION : Visualiser l'image avec une couleur selon la pr√©diction
        plt.subplot(2, 1, 2)
        # Cr√©er une superposition de couleur selon la pr√©diction
        if flood_class == 1:  # Si class√© comme inond√©
            # Afficher l'image avec une teinte rouge pour indiquer l'inondation
            plt.imshow(vv_band, cmap='gray')
            plt.imshow(np.ones_like(vv_band), cmap='autumn', alpha=0.5)
            title = f"ZONE INOND√âE (confiance: {flood_percentage:.1f}%)"
        else:
            # Afficher l'image avec une teinte bleue pour indiquer l'absence d'inondation
            plt.imshow(vv_band, cmap='gray')
            plt.imshow(np.zeros_like(vv_band), cmap='autumn', alpha=0.3)
            title = f"ZONE NON INOND√âE (confiance: {100-flood_percentage:.1f}%)"
        
        plt.title(title)
        plt.colorbar()
        plt.axis('off')
        
        plt.tight_layout()
        plt.savefig(output_path)
        
        # 7. D√©terminer le niveau de risque
        if flood_percentage < SEUIL_FAIBLE :
            risk_level = "Faible"
        elif flood_percentage < SEUIL_MOYEN:
            risk_level = "Mod√©r√©"
        elif flood_percentage < SEUIL_ELEV√â:
            risk_level = "√âlev√©"
        else:
            risk_level = "Tr√®s √©lev√©"
        
        # 8. Pr√©parer et retourner les r√©sultats
        result = {
            'success': True,
            'coordinates': {
                'longitude': longitude,
                'latitude': latitude,
                'bbox': bbox_coords
            },
            'prediction': {
                'flood_percentage': round(flood_percentage, 2),
                'confidence': round(confidence, 2),
                'risk_level': risk_level,
                'is_flooded': bool(flood_class)
            },
            'files': {
                'input_image': save_path,
                'output_visualization': output_path
            }
        }
        
        print(f"Analyse termin√©e! R√©sultat: {risk_level} risque d'inondation")
        print(f"Pourcentage de zone inond√©e: {flood_percentage:.2f}%")
        print(f"Confiance: {confidence:.2f}%")
        CACHE.save_prediction(longitude, latitude, size_km, start_date, end_date, result)

        return result
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {'success': False, 'error': str(e)}


""" √† ajouter logique lstm """




def predict_flood_from_image(image_path):
    """
    Fonction pour pr√©dire les inondations directement √† partir d'une image t√©l√©charg√©e
    Version modifi√©e pour utiliser rasterio avec les images TIF
    
    Args:
        image_path (str): Chemin vers l'image √† analyser
        
    Returns:
        dict: R√©sultat de la pr√©diction avec visualisation
    """
    try:
        print(f"Analyse de l'image: {image_path}")
        
        # Cr√©er le dossier de r√©sultats dans le r√©pertoire media pour accessibilit√© web
        from django.conf import settings
        results_dir = os.path.join(settings.MEDIA_ROOT, "resultats_image")
        os.makedirs(results_dir, exist_ok=True)

        # 1. Charger l'image (d√©tection automatique TIF vs autres formats)
        print("Chargement de l'image...")
        file_extension = os.path.splitext(image_path)[1].lower()
        is_tif = file_extension in ['.tif', '.tiff']
        
        if is_tif:
            # Utiliser rasterio pour les fichiers TIF
            import rasterio
            print("Chargement avec rasterio...")
            
            with rasterio.open(image_path) as src:
                image_data = src.read()
                
                # Extraire le canal d'affichage (m√™me logique que convertir_tif_avec_rasterio)
                if len(image_data.shape) == 3 and image_data.shape[0] > 1:
                    # Format rasterio: (bands, height, width)
                    display_band = image_data[0, :, :]
                    print(f"Utilisation de la premi√®re bande, forme: {display_band.shape}")
                    
                    # Pour le preprocessing, cr√©er une image 3D (H, W, C)
                    # Prendre les 2 premi√®res bandes si disponibles (VV, VH)
                    if image_data.shape[0] >= 2:
                        image = np.stack([image_data[0], image_data[1]], axis=-1)  # (H, W, 2)
                    else:
                        # Dupliquer la bande unique
                        image = np.stack([image_data[0], image_data[0]], axis=-1)  # (H, W, 2)
                else:
                    # Une seule bande
                    display_band = image_data.squeeze()
                    print(f"Bande unique, forme apr√®s squeeze: {display_band.shape}")
                    
                    # Cr√©er une image 3D en dupliquant la bande
                    image = np.stack([display_band, display_band], axis=-1)  # (H, W, 2)
                
                # Traitement des valeurs NoData
                if hasattr(src, 'nodata') and src.nodata is not None:
                    image = np.where(image == src.nodata, np.nan, image)
                    display_band = np.where(display_band == src.nodata, np.nan, display_band)
                
                # Filtrer les valeurs invalides
                image = np.nan_to_num(image, nan=0.0, posinf=0.0, neginf=0.0)
                display_band = np.nan_to_num(display_band, nan=0.0, posinf=0.0, neginf=0.0)
        else:
            # Utiliser PIL pour les autres formats
            from PIL import Image as PILImage
            print("Chargement avec PIL...")
            
            pil_image = PILImage.open(image_path)
            image = np.array(pil_image)
            
            # V√©rifier la dimension de l'image et convertir si n√©cessaire
            print(f"Forme de l'image originale: {image.shape}")
            
            if len(image.shape) == 2:
                # Image en niveaux de gris (H, W) -> (H, W, 2)
                display_band = image
                image = np.stack([image, image], axis=-1)
                print(f"Image convertie en 2 canaux. Nouvelle forme: {image.shape}")
            else:
                # Image couleur, prendre le premier canal pour l'affichage
                display_band = image[:,:,0] if image.shape[2] > 0 else image.squeeze()
                
                # S'assurer qu'on a exactement 2 canaux pour le mod√®le
                if image.shape[2] >= 2:
                    image = image[:,:,:2]  # Prendre les 2 premiers canaux
                else:
                    # Dupliquer le canal unique
                    image = np.stack([image.squeeze(), image.squeeze()], axis=-1)
        
        # V√©rification finale
        if image is None or np.isnan(image).any() or image.size == 0:
            print("‚ö†Ô∏è Image non disponible ou contenant des valeurs NaN")
            return {
                'success': False, 
                'error': "Image non valide ou contenant des valeurs NaN"
            }
        
        print(f"Image charg√©e avec succ√®s. Forme finale: {image.shape}")
        print(f"Display band forme: {display_band.shape}")
        
        # 2. Pr√©traiter l'image pour le mod√®le
        print("Pr√©traitement de l'image...")
        image_tensor = preprocess_sar_image_in_memory(
            image, 
            output_dir=os.path.join(settings.MEDIA_ROOT, "flood_prediction/temp"),
            visualize=False
        )
        
        # V√©rifier que le tenseur existe
        if image_tensor is None:
            raise ValueError("Le pr√©traitement de l'image a √©chou√© - image_tensor est None")
        
        print(f"Forme du tenseur d'image: {image_tensor.shape}")
        
        # Ajouter la dimension batch
        image_tensor = image_tensor.unsqueeze(0)
        
        # 3. Charger le mod√®le
        model_path = MODEL_PATH
        print(f"Chargement du mod√®le: {model_path}")
        model = load_model(model_path)
    
        # 4. Faire la pr√©diction
        print("Pr√©diction en cours...")
        model.eval()
        
        with torch.no_grad():
            outputs = model(image_tensor)
            # Convertir en probabilit√©s avec sigmoid
            flood_probability = torch.sigmoid(outputs[:, 1]).item()

            # Obtenir la classe pr√©dite (0=non inond√©, 1=inond√©)
            _, predicted = torch.max(outputs, 1)
            
            # Calculer les m√©triques
            flood_class = predicted.item()
            flood_percentage = flood_probability * 100
            confidence = max(flood_probability, 1 - flood_probability) * 100

        # 5. Cr√©er une visualisation
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_filename = f"flood_prediction_{timestamp}.png"
        output_path = os.path.join(results_dir, output_filename)
        
        plt.figure(figsize=(12, 12))
        
        # Visualiser l'image originale
        plt.subplot(2, 1, 1)
        plt.imshow(display_band, cmap='gray')
        plt.title("Image originale")
        plt.colorbar()
        plt.axis('off')
        
        # Visualiser l'image avec une couleur selon la pr√©diction
        plt.subplot(2, 1, 2)
        if flood_class == 1:  # Si class√© comme inond√©
            plt.imshow(display_band, cmap='gray')
            plt.imshow(np.ones_like(display_band), cmap='autumn', alpha=0.5)
            title = f"ZONE INOND√âE (confiance: {flood_percentage:.1f}%)"
        else:
            plt.imshow(display_band, cmap='gray')
            plt.imshow(np.zeros_like(display_band), cmap='autumn', alpha=0.3)
            title = f"ZONE NON INOND√âE (confiance: {100-flood_percentage:.1f}%)"
        
        plt.title(title)
        plt.colorbar()
        plt.axis('off')
        
        plt.tight_layout()
        plt.savefig(output_path)
        plt.close()  # Fermer la figure pour lib√©rer la m√©moire
        
        # 6. D√©terminer le niveau de risque
        if flood_percentage < SEUIL_FAIBLE:
            risk_level = "Faible"
        elif flood_percentage < SEUIL_MOYEN:
            risk_level = "Mod√©r√©"
        elif flood_percentage < SEUIL_ELEV√â:
            risk_level = "√âlev√©"
        else:
            risk_level = "Tr√®s √©lev√©"
        
        # 7. Pr√©parer et retourner les r√©sultats
        result = {
            'success': True,
            'prediction': {
                'flood_percentage': round(flood_percentage, 2),
                'confidence': round(confidence, 2),
                'risk_level': risk_level,
                'is_flooded': bool(flood_class)
            },
            'files': {
                'input_image': image_path,
                'output_visualization': output_path,
                'output_filename': output_filename
            }
        }
        
        print(f"Analyse termin√©e! R√©sultat: {risk_level} risque d'inondation")
        print(f"Pourcentage de zone inond√©e: {flood_percentage:.2f}%")
        print(f"Confiance: {confidence:.2f}%")

        return result
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {'success': False, 'error': str(e)}
    
def convertir_tif_avec_rasterio(tif_path, png_path):
    """
    Convertit une image TIF SAR en PNG en utilisant rasterio avec am√©liorations visuelles
    
    Args:
        tif_path (str): Chemin de l'image TIF SAR
        png_path (str): Chemin o√π sauvegarder le PNG
        
    Returns:
        str: Chemin du fichier PNG cr√©√© ou None en cas d'erreur
    """
    import rasterio
    import numpy as np
    import matplotlib.pyplot as plt
    import os
    from matplotlib import colors
    
    try:
        print(f"Chargement avec rasterio: {tif_path}")
        
        # 1. Ouvrir l'image avec rasterio
        with rasterio.open(tif_path) as src:
            # Lire toutes les bandes
            image_data = src.read()
            print(f"Forme des donn√©es rasterio: {image_data.shape}")
            print(f"Nombre de bandes: {src.count}")
            print(f"Dimensions: {src.width} x {src.height}")
            print(f"Type de donn√©es: {image_data.dtype}")
            
            # 2. Extraire le canal d'affichage
            if len(image_data.shape) == 3 and image_data.shape[0] > 1:
                display_band = image_data[0, :, :]
                print(f"Utilisation de la premi√®re bande, forme: {display_band.shape}")
            else:
                display_band = image_data.squeeze()
                print(f"Bande unique, forme apr√®s squeeze: {display_band.shape}")
        
        # 3. Traitement avanc√© des valeurs pour am√©liorer la clart√©
        # Remplacer les valeurs NoData
        if hasattr(src, 'nodata') and src.nodata is not None:
            display_band = np.where(display_band == src.nodata, np.nan, display_band)
        
        # Filtrer les valeurs invalides
        display_band = np.nan_to_num(display_band, nan=0.0, posinf=0.0, neginf=0.0)
        
        # Am√©lioration du contraste et de la clart√©
        valid_pixels = display_band[display_band > 0]  # Exclure les pixels √† 0 (background)
        
        if len(valid_pixels) > 0:
            # Utiliser les percentiles pour un meilleur contraste
            p1, p99 = np.percentile(valid_pixels, (1, 99))
            p5, p95 = np.percentile(valid_pixels, (5, 95))
            
            print(f"Statistiques des pixels valides:")
            print(f"  Min: {np.min(valid_pixels):.3f}, Max: {np.max(valid_pixels):.3f}")
            print(f"  Percentiles 1-99: {p1:.3f} - {p99:.3f}")
            print(f"  Percentiles 5-95: {p5:.3f} - {p95:.3f}")
            
            # Normalisation pour am√©liorer le contraste
            display_normalized = np.clip(display_band, p1, p99)
            
            # Application d'une correction gamma pour am√©liorer la visibilit√©
            gamma = 0.8  # Valeur < 1 pour √©claircir l'image
            display_gamma = np.power(display_normalized / np.max(display_normalized), gamma)
            
            vmin, vmax = p5, p95  # Utiliser p5-p95 pour l'affichage
        else:
            display_normalized = display_band
            display_gamma = display_band
            vmin, vmax = None, None
        
        # 4. Cr√©er une visualisation am√©lior√©e
        plt.figure(figsize=(14, 12), dpi=120)  # Augmenter la r√©solution
        
        # Image originale avec am√©lioration du contraste
        plt.subplot(2, 1, 1)
        im1 = plt.imshow(display_normalized, cmap='gray', vmin=vmin, vmax=vmax)
        plt.colorbar(im1, label='Intensit√© normalis√©e', fraction=0.046, pad=0.04)
        plt.title("Image SAR originale (VV) - Contraste am√©lior√©", fontsize=14, fontweight='bold')
        plt.axis('off')
        
        # Image avec correction gamma et superposition
        plt.subplot(2, 1, 2)
        # Utiliser une colormap qui am√©liore les d√©tails
        im2 = plt.imshow(display_gamma, cmap='viridis', alpha=0.9)
        
        # Superposition avec transparence r√©duite pour ne pas masquer les d√©tails
        overlay = plt.imshow(np.zeros_like(display_band), cmap='autumn', alpha=0.2)
        
        plt.colorbar(im2, label='Intensit√© avec correction gamma', fraction=0.046, pad=0.04)
        plt.title("Image SAR - Vue d'analyse am√©lior√©e", fontsize=14, fontweight='bold')
        plt.axis('off')
        
        # Ajouter des informations sur l'am√©lioration
        info_text = f"Am√©liorations appliqu√©es:\n‚Ä¢ Normalisation percentiles 1-99%\n‚Ä¢ Correction gamma Œ≥={gamma}\n‚Ä¢ Contraste optimis√©"
        plt.figtext(0.02, 0.02, info_text, fontsize=9, 
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        
        # 5. Sauvegarder avec une meilleure qualit√©
        plt.tight_layout()
        plt.savefig(png_path, dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"‚úÖ Image convertie avec rasterio (version am√©lior√©e): {png_path}")
        return png_path
        
    except Exception as e:
        print(f"‚ùå Erreur avec rasterio: {str(e)}")
        import traceback
        traceback.print_exc()
        return None



def convertir_tif_sar_detaille(tif_path, png_path, is_flood=False, flood_percentage=None):
    """
    Version d√©taill√©e avec rasterio qui reproduit exactement predict_flood
    
    Args:
        tif_path (str): Chemin de l'image TIF SAR
        png_path (str): Chemin o√π sauvegarder le PNG
        is_flood (bool): Indique si c'est une zone inond√©e
        flood_percentage (float): Pourcentage d'inondation
        
    Returns:
        str: Chemin du fichier PNG cr√©√©
    """
    import rasterio
    import numpy as np
    import matplotlib.pyplot as plt
    from datetime import datetime
    
    try:
        print(f"Traitement d√©taill√© avec rasterio: {tif_path}")
        
        # 1. Charger avec rasterio
        with rasterio.open(tif_path) as src:
            # Lire la premi√®re bande (VV)
            vv_band = src.read(1)
            print(f"Bande VV charg√©e, forme: {vv_band.shape}, type: {vv_band.dtype}")
            
            # Informations sur l'image
            print(f"CRS: {src.crs}")
            print(f"Transform: {src.transform}")
            print(f"Bounds: {src.bounds}")
        
        # 2. Traitement des donn√©es (comme dans predict_flood)
        # G√©rer les valeurs NoData
        vv_band = np.nan_to_num(vv_band, nan=0.0, posinf=0.0, neginf=0.0)
        
        # 3. Cr√©er la visualisation (reproduction exacte de predict_flood)
        plt.figure(figsize=(12, 12))
        
        # Visualiser l'image VV originale
        plt.subplot(2, 1, 1)
        plt.imshow(vv_band, cmap='gray')
        plt.title("Image SAR originale (VV)")
        plt.colorbar()
        plt.axis('off')
        
        # Visualiser l'image avec une couleur selon la pr√©diction
        plt.subplot(2, 1, 2)
        # Cr√©er une superposition de couleur selon la pr√©diction
        if is_flood:  # Si class√© comme inond√©
            # Afficher l'image avec une teinte rouge pour indiquer l'inondation
            plt.imshow(vv_band, cmap='gray')
            plt.imshow(np.ones_like(vv_band), cmap='autumn', alpha=0.5)
            title = f"ZONE INOND√âE"
            if flood_percentage is not None:
                title += f" (confiance: {flood_percentage:.1f}%)"
        else:
            # Afficher l'image avec une teinte bleue pour indiquer l'absence d'inondation
            plt.imshow(vv_band, cmap='gray')
            plt.imshow(np.zeros_like(vv_band), cmap='autumn', alpha=0.3)
            title = f"ZONE NON INOND√âE"
            if flood_percentage is not None:
                title += f" (confiance: {(100-flood_percentage):.1f}%)"
        
        plt.title(title)
        plt.colorbar()
        plt.axis('off')
        
        plt.tight_layout()
        plt.savefig(png_path)
        plt.close()
        
        print(f"‚úÖ Visualisation d√©taill√©e sauvegard√©e: {png_path}")
        return png_path
        
    except Exception as e:
        print(f"‚ùå Erreur: {str(e)}")
        import traceback
        traceback.print_exc()
        return None
    

def predict_flood_with_unet(image_path, threshold=0.5):
    """
    Performs flood segmentation using U-Net model with enhanced visualization
    
    Args:
        image_path: Path to the input image (supports TIF and regular formats)
        threshold: Threshold for binarizing probabilities (default: 0.3)
        
    Returns:
        Dictionary with prediction results and file paths
    """
    import torch
    import numpy as np
    import rasterio
    import matplotlib.pyplot as plt
    from skimage.transform import resize
    from datetime import datetime
    import os
    from django.conf import settings
    
    try:
        print(f"üîÑ Analyse U-Net de l'image: {image_path}")
        
        # Configuration
        CHECKPOINT = os.path.join(settings.BASE_DIR, "flood_prediction", "models", "model_20230412_015857_48")
        if not os.path.exists(CHECKPOINT):
            # Fallback √† un chemin absolu si le chemin relatif √©choue
            CHECKPOINT = 'C:/Users/mokht/Desktop/PDS/Pytorch-UNet-Flood-Segmentation/models/model_20230412_015857_48'
        
        API_DEM = "13ab4c018a6ab1b00e771d400d424345"
        THRESHOLD = threshold
        
        # Cr√©er les dossiers de r√©sultats
        results_dir = os.path.join(settings.MEDIA_ROOT, "resultats_image")
        temp_dir = os.path.join(settings.MEDIA_ROOT, "temp_images")
        os.makedirs(results_dir, exist_ok=True)
        os.makedirs(temp_dir, exist_ok=True)
        
        # V√©rifier le type de fichier
        file_extension = os.path.splitext(image_path)[1].lower()
        is_tif = file_extension in ['.tif', '.tiff']
        
        # Si ce n'est pas un TIF et qu'on veut quand m√™me proc√©der
        if not is_tif:
            print("‚ö†Ô∏è Attention: U-Net fonctionne mieux avec des images TIF SAR")
        
        # 1. Charger l'image avec rasterio ou PIL selon le format
        if is_tif:
            with rasterio.open(image_path) as src:
                vv = src.read(1).astype(np.float32)
                profile = src.profile.copy()
                bounds = src.bounds
                west, south, east, north = bounds.left, bounds.bottom, bounds.right, bounds.top
                print(f"Coordonn√©es: {south:.6f}¬∞S, {north:.6f}¬∞N, {west:.6f}¬∞E, {east:.6f}¬∞E")
            
            # Pour VH, utiliser la m√™me image (simulation)
            vh = vv.copy() - 6.0  # VH typiquement plus faible que VV
        else:
            # Utiliser PIL pour les formats non-TIF
            from PIL import Image
            img = Image.open(image_path).convert('L')  # Convertir en niveaux de gris
            vv = np.array(img).astype(np.float32)
            
            # Normaliser les valeurs entre -25 et 0 dB (simulation donn√©es SAR)
            vv = -25 + 25 * (vv / 255.0)
            vh = vv - 6.0  # Simuler VH
            
            # Simuler des m√©tadonn√©es g√©ographiques
            south, north, west, east = 0, 1, 0, 1
            
        # 2. Pr√©traitement SAR
        vv = np.clip(vv, -50, 25)
        vh = np.clip(vh, -50, 25)
        vv_norm = (vv - (-50)) / (25 - (-50))
        vh_norm = (vh - (-50)) / (25 - (-50))
        
        h, w = vv.shape
        target_shape = (h, w)
        print(f"Dimensions originales: {h}x{w}")
        
        # 3. G√©n√©rer des donn√©es DEM et pr√©cipitations
        try:
            # Essayer d'utiliser coordonnees_vers_tenseur si disponible
            ele_norm = coordonnees_vers_tenseur(
                south=south, north=north, west=west, east=east,
                dem_type="SRTM", api_key=API_DEM, target_shape=target_shape,
                clip_min=0.0, clip_max=2000.0
            ).squeeze().numpy()
        except:
            # Cr√©er un tenseur synth√©tique si la fonction n'est pas disponible
            x = np.linspace(0, 1, w)
            y = np.linspace(0, 1, h)
            X, Y = np.meshgrid(x, y)
            ele_norm = (np.sin(X*3) * np.cos(Y*3) * 0.5 + 0.5)
        
        try:
            # Essayer d'utiliser obtenir_precipitation_historique si disponible
            wat_norm = obtenir_precipitation_historique(
                south=south, north=north, west=west, east=east,
                date=datetime.now().strftime('%Y-%m-%d'), 
                target_shape=target_shape,
                is_normalized=True
            ).squeeze().numpy()
        except:
            # Cr√©er un tenseur synth√©tique si la fonction n'est pas disponible
            wat_norm = np.random.uniform(0, 0.5, size=target_shape)
        
        # 4. Redimensionner pour U-Net (multiple de 16)
        h_target = ((h + 15) // 16) * 16
        w_target = ((w + 15) // 16) * 16
        print(f"Redimensionnement: {h}√ó{w} ‚Üí {h_target}√ó{w_target}")
        
        vv_resized = resize(vv_norm, (h_target, w_target), mode='edge', preserve_range=True)
        vh_resized = resize(vh_norm, (h_target, w_target), mode='edge', preserve_range=True)
        dem_resized = resize(ele_norm, (h_target, w_target), mode='edge', preserve_range=True)
        pwat_resized = resize(wat_norm, (h_target, w_target), mode='edge', preserve_range=True)
        
        # 5. Cr√©er le tenseur d'entr√©e
        img = np.stack([vv_resized, vh_resized, dem_resized, pwat_resized], axis=0)
        tensor = torch.from_numpy(img).unsqueeze(0).float()
        
        # 6. Charger et ex√©cuter le mod√®le
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"üíª Device: {device}")
        
        # Charger le mod√®le U-Net
        from .unet.models import Unet  # Assurez-vous que ce chemin est correct
        model = Unet(in_channels=4, out_channels=1)
        model.to(device)
        
        try:
            state = torch.load(CHECKPOINT, map_location=device)
            model.load_state_dict(state)
        except Exception as e:
            print(f"Erreur lors du chargement du mod√®le: {e}")
            # Cr√©er des r√©sultats synth√©tiques si le mod√®le ne peut pas √™tre charg√©
            prediction = np.random.random((h_target, w_target)) * 0.5
        else:
            # Inf√©rence avec le mod√®le
            model.eval()
            tensor = tensor.to(device)
            with torch.no_grad():
                prediction = model(tensor).squeeze().cpu().numpy()
        
        # Redimensionner √† la taille originale
        probability_map = resize(prediction, (h, w), mode='edge', preserve_range=True)
        
        # 7. Cr√©er le masque binaire
        mask_binary = (probability_map > THRESHOLD).astype(np.uint8)
        pourcentage_inondation = 100 * np.sum(mask_binary == 1) / mask_binary.size
        
        print(f"Pourcentage de pixels inond√©s: {pourcentage_inondation:.2f}%")
        
        # 8. Sauvegarder le masque en tant que GeoTIFF
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        mask_filename = f"unet_mask_{timestamp}.tif"
        mask_path = os.path.join(temp_dir, mask_filename)
        
        # Si l'image est un TIF, conserver les m√©tadonn√©es spatiales
        if is_tif and 'profile' in locals():
            profile.update(dtype=rasterio.uint8, count=1, compress='lzw')
            with rasterio.open(mask_path, 'w', **profile) as dst:
                dst.write(mask_binary, 1)
        else:
            # Cr√©er un GeoTIFF simple sans m√©tadonn√©es spatiales
            with rasterio.open(mask_path, 'w', 
                              driver='GTiff', 
                              height=h, width=w,
                              count=1, dtype=rasterio.uint8,
                              compress='lzw') as dst:
                dst.write(mask_binary, 1)
        
        # 9. Cr√©er une visualisation standard (comme CNN pour coh√©rence)
        output_filename = f"unet_prediction_{timestamp}.png"
        output_path = os.path.join(results_dir, output_filename)
        
        plt.figure(figsize=(12, 12))
        
        # Image originale
        plt.subplot(2, 1, 1)
        plt.imshow(vv_norm, cmap='viridis')
        plt.colorbar(label='Intensit√© SAR normalis√©e')
        plt.title("Image SAR originale", fontsize=14)
        plt.axis('off')
        
        # R√©sultat avec masque
        plt.subplot(2, 1, 2)
        plt.imshow(vv_norm, cmap='gray')

        if pourcentage_inondation > threshold:  # Si au moins quelques pixels inond√©s
            masked = np.ma.masked_where(mask_binary == 0, mask_binary)
            plt.imshow(masked, cmap='cool', alpha=0.7)
            title_color = 'blue'
        else:
            title_color = 'green'
        
        plt.title(f"Segmentation U-Net: {pourcentage_inondation:.2f}% inond√©", 
                 fontsize=14, color=title_color)
        plt.axis('off')
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        # 10. D√©terminer le niveau de risque
        if pourcentage_inondation < SEUIL_FAIBLE:
            risk_level = "Faible"
        elif pourcentage_inondation < SEUIL_MOYEN:
            risk_level = "Mod√©r√©"
        elif pourcentage_inondation < SEUIL_ELEV√â:
            risk_level = "√âlev√©"
        else:
            risk_level = "Tr√®s √©lev√©"
        
        # 11. Pr√©parer le r√©sultat d√©taill√©
        result = {
            'success': True,
            'prediction': {
                'flood_percentage': round(pourcentage_inondation, 2),
                'confidence': 95.0,  # Valeur fixe pour l'exemple
                'risk_level': risk_level,
                'is_flooded': pourcentage_inondation > 5,
                'threshold': THRESHOLD
            },
            'files': {
                'input_image': image_path,
                'output_visualization': output_path,
                'mask_path': mask_path
            },
            'probability_map': probability_map,  # Carte de probabilit√© pour visualisation d√©taill√©e
            'metadata': {
                'model': 'U-Net',
                'checkpoint': os.path.basename(CHECKPOINT),
                'input_dimensions': f"{h}x{w}",
                'processing_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        }
        
        print(f"‚úÖ Analyse U-Net termin√©e: {risk_level} risque ({pourcentage_inondation:.2f}%)")
        print(f"üìä Visualisation: {output_path}")
        print(f"üó∫Ô∏è Masque GeoTIFF: {mask_path}")
        return result
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {'success': False, 'error': str(e)}

def create_unet_mask_visualization_like_cnn(vv_norm, mask_binary, output_path, pourcentage_inondation):
    """
    Cr√©e la visualisation U-Net dans le m√™me style que CNN (2 sous-graphiques)
    
    Args:
        vv_norm: Image SAR normalis√©e
        mask_binary: Masque binaire de segmentation
        output_path: Chemin de sauvegarde
        pourcentage_inondation: Pourcentage de pixels inond√©s
    """
    import matplotlib.pyplot as plt
    import numpy as np
    
    # Style identique √† predict_flood_from_image
    plt.figure(figsize=(12, 12))
    
    # 1. Image originale (comme CNN)
    plt.subplot(2, 1, 1)
    plt.imshow(vv_norm, cmap='gray')
    plt.title("Image originale")
    plt.colorbar()
    plt.axis('off')
    
    # 2. R√©sultat de segmentation avec masque (comme CNN mais adapt√© U-Net)
    plt.subplot(2, 1, 2)
    
    # Afficher l'image en arri√®re-plan
    plt.imshow(vv_norm, cmap='gray')
    
    # Superposer le masque selon le pourcentage d'inondation
    if pourcentage_inondation > 10:  # Si zone consid√©r√©e comme inond√©e
        # Superposer le masque en rouge/orange pour les zones inond√©es
        if np.sum(mask_binary) > 0:
            masked_overlay = np.where(mask_binary == 1, 1, 0)
            plt.imshow(masked_overlay, cmap='autumn', alpha=0.6, vmin=0, vmax=1)
        
        title = f"ZONE INOND√âE (U-Net: {pourcentage_inondation:.1f}%)"
        title_color = 'red'
    else:
        # L√©ger overlay pour indiquer "pas d'inondation"
        plt.imshow(np.zeros_like(vv_norm), cmap='autumn', alpha=0.2)
        title = f"ZONE NON INOND√âE (U-Net: {pourcentage_inondation:.1f}%)"
        title_color = 'green'
    
    plt.title(title, color=title_color, fontweight='bold')
    plt.colorbar()
    plt.axis('off')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight', facecolor='white')
    plt.close()  # Fermer pour lib√©rer la m√©moire
    
    print(f"‚úÖ Visualisation U-Net (style CNN) sauvegard√©e: {output_path}")



def create_unet_visualization(image_path):
    """
    Fonction simple qui utilise U-Net existant et g√©n√®re une visualisation GeoTIFF du masque
    
    Args:
        image_path (str): Chemin vers l'image TIF d'entr√©e
        
    Returns:
        dict: R√©sultat avec chemin de la visualisation g√©n√©r√©e
    """
    
    try:
        from .unet.models import Unet
        from .unet.build_sequence_unet import coordonnees_vers_tenseur, obtenir_precipitation_historique
    except ImportError:
        return {
            'success': False,
            'error': "Modules U-Net non trouv√©s"
        }
    
    try:
        print(f"üîÑ Cr√©ation visualisation U-Net pour: {image_path}")
        
        # Configuration
        CHECKPOINT = 'C:/Users/mokht/Desktop/PDS/Pytorch-UNet-Flood-Segmentation/models/model_20230411_161404_31'
        CHECKPOINT2 = 'C:/Users/mokht/Desktop/PDS/Pytorch-UNet-Flood-Segmentation/models/model_20230412_015857_48'
        API_DEM = "13ab4c018a6ab1b00e771d400d424345"
        THRESHOLD = 0.0075
        
        # Dossier de sortie
        output_dir = os.path.join(settings.MEDIA_ROOT, "unet_visualizations")
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. Charger l'image avec rasterio
        with rasterio.open(image_path) as src:
            vv = src.read(1).astype(np.float32)
            profile = src.profile.copy()  # Copier le profil pour la sortie
            bounds = src.bounds
            west, south, east, north = bounds.left, bounds.bottom, bounds.right, bounds.top
            transform = src.transform
        
        vh = vv.copy()  # Simulation VH
        h, w = vv.shape
        
        # 2. Pr√©traitement SAR
        vv_clipped = np.clip(vv, -50, 25)
        vh_clipped = np.clip(vh, -50, 25)
        vv_norm = (vv_clipped - (-50)) / (25 - (-50))
        vh_norm = (vh_clipped - (-50)) / (25 - (-50))
        
        # 3. Donn√©es auxiliaires (DEM et pr√©cipitation avec fallback)
        try:
            dem_tensor = coordonnees_vers_tenseur(
                south=south, north=north, west=west, east=east,
                dem_type="SRTM", api_key=API_DEM, target_shape=(h, w),
                clip_min=0.0, clip_max=2000.0
            )
            ele_norm = dem_tensor.squeeze().numpy()
        except:
            ele_norm = np.zeros((h, w), dtype=np.float32)
        
        try:
            precip_tensor = obtenir_precipitation_historique(
                south=south, north=north, west=west, east=east,
                date=datetime.now().strftime('%Y-%m-%d'), target_shape=(h, w)
            )
            wat_norm = precip_tensor.squeeze().numpy()
        except:
            wat_norm = np.zeros((h, w), dtype=np.float32)
        
        # 4. Redimensionner pour U-Net (multiple de 16)
        from skimage.transform import resize
        h_target = ((h + 15) // 16) * 16
        w_target = ((w + 15) // 16) * 16
        
        vv_resized = resize(vv_norm, (h_target, w_target), preserve_range=True)
        vh_resized = resize(vh_norm, (h_target, w_target), preserve_range=True)
        dem_resized = resize(ele_norm, (h_target, w_target), preserve_range=True)
        pwat_resized = resize(wat_norm, (h_target, w_target), preserve_range=True)
        
        # 5. Inf√©rence U-Net
        img = np.stack([vv_resized, vh_resized, dem_resized, pwat_resized], axis=0)
        tensor = torch.from_numpy(img).unsqueeze(0).float()
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = Unet(in_channels=4, out_channels=1)
        model.to(device)
        state = torch.load(CHECKPOINT, map_location=device)
        model.load_state_dict(state)
        model.eval()
        
        tensor = tensor.to(device)
        with torch.no_grad():
            prediction = model(tensor).squeeze().cpu().numpy()
        
        # Recadrer √† la taille originale
        prediction_original = resize(prediction, (h, w), preserve_range=True)
        
        # 6. Cr√©er le masque binaire
        mask_binary = (prediction_original > THRESHOLD).astype(np.uint8)
        pourcentage_inondation = 100 * np.sum(mask_binary == 1) / mask_binary.size
        
        # 7. Sauvegarder en GeoTIFF
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_filename = f"unet_mask_{timestamp}.tif"
        output_path = os.path.join(output_dir, output_filename)
        
        # Mettre √† jour le profil pour la sortie
        profile.update({
            'dtype': 'uint8',
            'count': 1,
            'compress': 'lzw'
        })
        
        # √âcrire le masque en GeoTIFF
        with rasterio.open(output_path, 'w', **profile) as dst:
            dst.write(mask_binary, 1)
        
        print(f"‚úÖ Masque U-Net sauvegard√© en GeoTIFF: {output_path}")
        print(f"üìä Pourcentage inond√©: {pourcentage_inondation:.2f}%")
        
        return {
            'success': True,
            'mask_path': output_path,
            'flood_percentage': round(pourcentage_inondation, 2),
            'input_image': image_path
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {'success': False, 'error': str(e)}


def test_unet_visualization():
    """
    Test simple pour create_unet_visualization
    """
    import rasterio  # Ajouter l'import manquant
    import numpy as np
    import os
    from rasterio.transform import from_bounds
    
    print("üß™ Test de cr√©ation visualisation U-Net")
    
    # Chemin d'image de test
    test_image = "C:/Users/mokht/Desktop/PDS/flood_dataset/SEN12FLOOD/0167/S1B_IW_GRDH_1SDV_20190314T160711_20190314T160736_015352_01CBEE_7F77_corrected_VV.tif"

    # Cr√©er une image de test si elle n'existe pas
    if not os.path.exists(test_image):
        print("üìÅ Cr√©ation d'une image de test...")
        
        os.makedirs(os.path.dirname(test_image), exist_ok=True)
        
        # Image SAR factice avec g√©or√©f√©rencement
        fake_data = np.random.uniform(-30, -10, (256, 256)).astype(np.float32)
        transform = from_bounds(2.0, 46.0, 3.0, 47.0, 256, 256)  # Coordonn√©es France
        
        profile = {
            'driver': 'GTiff',
            'height': 256,
            'width': 256,
            'count': 1,
            'dtype': 'float32',
            'crs': 'EPSG:4326',
            'transform': transform
        }
        
        with rasterio.open(test_image, 'w', **profile) as dst:
            dst.write(fake_data, 1)
        
        print(f"‚úÖ Image de test cr√©√©e: {test_image}")
    
    # Test de la fonction
    print(f"üîÑ Test avec l'image: {test_image}")
    result = create_unet_visualization(test_image)
    
    if result['success']:
        print("‚úÖ Visualisation U-Net cr√©√©e avec succ√®s!")
        print(f"   Masque GeoTIFF: {result['mask_path']}")
        print(f"   Pourcentage inond√©: {result['flood_percentage']}%")
        
        # V√©rifier que le fichier existe
        if os.path.exists(result['mask_path']):
            print("‚úÖ Fichier GeoTIFF v√©rifi√©")
            
            # Afficher les informations du fichier
            with rasterio.open(result['mask_path']) as src:
                print(f"   Dimensions: {src.width}x{src.height}")
                print(f"   CRS: {src.crs}")
                print(f"   Type: {src.dtypes[0]}")
        else:
            print("‚ùå Fichier GeoTIFF non trouv√©")
    else:
        print(f"‚ùå Erreur: {result['error']}")

def visualiser_tif(tif_path, save_png=True, clip_percentile=True):
    """
    Visualise une image TIFF avec rendu am√©lior√© et sauvegarde automatique en PNG
    
    Args:
        tif_path: Chemin vers l'image TIFF √† visualiser
        save_png: Bool√©en, sauvegarder l'image en PNG ou non (par d√©faut True)
        clip_percentile: Si True, utilise une m√©thode robuste pour l'√©tirement de contraste
    """
    print(f"üîç Visualisation du fichier: {tif_path}")
    
    # Charger l'image TIFF
    with rasterio.open(tif_path) as src:
        band = src.read(1)
        print(f"Dimensions: {band.shape}, Type: {band.dtype}, Min: {band.min()}, Max: {band.max()}")
    
    # Traitement sp√©cifique pour les images SAR
    if band.min() < -10 and ("VV" in tif_path or "VH" in tif_path):
        print("Image SAR d√©tect√©e - Am√©lioration du contraste")
        
        # La "plage" est l'intervalle de valeurs utilis√© pour l'affichage
        # On utilise les percentiles pour √©liminer les valeurs extr√™mes
        if clip_percentile:
            vmin, vmax = np.percentile(band[band > -100], [2, 98])
            print(f"Plage utilis√©e (2-98%): [{vmin:.2f}, {vmax:.2f}] dB")
        else:
            vmin, vmax = -25, 0
            print(f"Plage standard SAR: [{vmin:.2f}, {vmax:.2f}] dB")
        
        # Am√©lioration du contraste en limitant les valeurs et normalisant
        band_display = np.clip(band, vmin, vmax)
        band_display = (band_display - vmin) / (vmax - vmin)
        
        plt.figure(figsize=(16, 12))
        img = plt.imshow(band_display, cmap='viridis')
        plt.colorbar(img, label='Intensit√© SAR (dB normalis√©e)', shrink=0.8, pad=0.02)
        plt.title(f"Image SAR: {os.path.basename(tif_path)}\n"
                 f"Dimensions: {band.shape[0]}√ó{band.shape[1]} pixels\n"
                 f"Plage d'affichage: [{vmin:.2f}, {vmax:.2f}] dB\n"
                 f"Valeurs r√©elles: [{band.min():.2f}, {band.max():.2f}] dB", 
                 fontsize=14, pad=20)
        
    # Pour les masques binaires (0-1)
    elif np.array_equal(np.unique(band), [0, 1]) or np.array_equal(np.unique(band), [0, 1, 255]):
        print("Masque binaire d√©tect√©")
        unique_values = np.unique(band)
        percent_one = 100 * np.sum(band > 0) / band.size
        
        plt.figure(figsize=(16, 12))
        img = plt.imshow(band, cmap='Blues')
        plt.colorbar(img, label='Classe (0=Non-inond√©, 1=Inond√©)', shrink=0.8, pad=0.02)
        plt.title(f"Masque de segmentation: {os.path.basename(tif_path)}\n"
                 f"Dimensions: {band.shape[0]}√ó{band.shape[1]} pixels\n"
                 f"Valeurs uniques: {unique_values}\n"
                 f"Pixels inond√©s: {percent_one:.2f}% ({np.sum(band > 0):,} pixels)\n"
                 f"Pixels non-inond√©s: {100-percent_one:.2f}% ({np.sum(band == 0):,} pixels)",
                 fontsize=14, pad=20)
        
    # Autres images (DEM, pr√©cipitations, etc.)
    else:
        print("Autre type d'image d√©tect√©")
        if clip_percentile:
            # La "plage" pour les autres images = intervalle de valeurs pour l'affichage
            vmin, vmax = np.percentile(band[np.isfinite(band)], [2, 98])
            print(f"Plage utilis√©e (2-98%): [{vmin:.2f}, {vmax:.2f}]")
        else:
            vmin, vmax = band.min(), band.max()
            print(f"Plage compl√®te: [{vmin:.2f}, {vmax:.2f}]")
        
        band_display = np.clip(band, vmin, vmax)
        band_display = (band_display - vmin) / (vmax - vmin)
        
        plt.figure(figsize=(16, 12))
        img = plt.imshow(band_display, cmap='viridis')
        plt.colorbar(img, label='Valeur normalis√©e', shrink=0.8, pad=0.02)
        plt.title(f"Image: {os.path.basename(tif_path)}\n"
                 f"Dimensions: {band.shape[0]}√ó{band.shape[1]} pixels\n"
                 f"Plage d'affichage: [{vmin:.2f}, {vmax:.2f}]\n"
                 f"Valeurs r√©elles: [{band.min():.2f}, {band.max():.2f}]\n"
                 f"Type de donn√©es: {band.dtype}",
                 fontsize=14, pad=20)
    
    plt.axis('off')
    plt.tight_layout()
    
    # Sauvegarder en PNG avec d√©tails
    if save_png:
        base_name = os.path.splitext(os.path.basename(tif_path))[0]
        output_dir = os.path.dirname(tif_path)
        png_path = os.path.join(output_dir, f"{base_name}_visualisation_detaillee.png")
        
        plt.savefig(png_path, bbox_inches='tight', dpi=300, facecolor='white', 
                   edgecolor='none', pad_inches=0.2)
        print(f"üì∑ Image d√©taill√©e sauvegard√©e: {png_path}")
        
        # Cr√©er aussi une version avec m√©tadonn√©es dans le nom
        from datetime import datetime
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        detailed_png = os.path.join(output_dir, f"{base_name}_analyse_{timestamp}.png")
        plt.savefig(detailed_png, bbox_inches='tight', dpi=300, facecolor='white')
        print(f"üì∑ Version timestamp√©e: {detailed_png}")
    
    plt.show()
    return band

def visualiser_resultat_segmentation(vv_path, masque_path, proba_map=None, output_png=None, threshold=0.5):
    """
    Visualise l'image SAR originale et sa segmentation avec d√©tails complets
    
    Args:
        vv_path: Chemin de l'image SAR VV
        masque_path: Chemin du masque de segmentation
        proba_map: Carte de probabilit√©s brute (sortie du mod√®le avant seuil)
        output_png: Chemin de sortie pour l'image
        threshold: Seuil utilis√© pour la binarisation (pour affichage)
    """
    print("üìä Visualisation d√©taill√©e des r√©sultats...")
    
    # 1. Charger les images et v√©rifier les dimensions
    with rasterio.open(vv_path) as src:
        vv = src.read(1).astype(np.float32)
        print(f"Image VV charg√©e: forme={vv.shape}")
        vv_profile = src.profile
    
    with rasterio.open(masque_path) as src:
        mask = src.read(1)
        print(f"Masque charg√©: forme={mask.shape}")
        # V√©rifier le contenu du masque
        unique_values = np.unique(mask)
        print(f"Valeurs uniques dans le masque: {unique_values}")
    
    # 2. V√©rifier la correspondance des dimensions
    if vv.shape != mask.shape:
        print(f"‚ö†Ô∏è ATTENTION: Les dimensions ne correspondent pas! VV:{vv.shape}, masque:{mask.shape}")
    
    # 3. Normalisation du masque si n√©cessaire (pour le cas o√π il y a des valeurs 255)
    if 255 in unique_values:
        print("Normalisation du masque (255 ‚Üí 1)")
        mask = (mask > 0).astype(np.uint8)
    
    # 4. Pr√©traitement pour visualisation (am√©liorer le contraste)
    p_min, p_max = np.percentile(vv[vv > -100], [2, 98])
    print(f"Plage de normalisation SAR: [{p_min:.2f}, {p_max:.2f}]")
    vv_display = np.clip(vv, p_min, p_max)
    vv_norm = (vv_display - vv_display.min()) / (vv_display.max() - vv_display.min())
    
    # 5. Calcul des statistiques d√©taill√©es
    pourcentage_inondation = 100 * np.sum(mask == 1) / mask.size
    nb_pixels_inond√©s = np.sum(mask == 1)
    nb_pixels_total = mask.size
    
    print(f"Pourcentage de pixels inond√©s: {pourcentage_inondation:.2f}%")
    print(f"Pixels inond√©s: {nb_pixels_inond√©s:,} / {nb_pixels_total:,}")
    
    # 6. Configuration de la figure avec plus d'espace
    n_plots = 3 if proba_map is not None else 2
    plt.figure(figsize=(8*n_plots, 10))
    
    # 7. Image originale (premi√®re sous-figure)
    plt.subplot(2, n_plots, 1)
    plt.imshow(vv_norm, cmap='viridis')
    plt.colorbar(label='Intensit√© SAR normalis√©e', shrink=0.8)
    plt.title(f"Image SAR originale (VV)\n"
             f"Dimensions: {vv.shape[0]}√ó{vv.shape[1]} pixels\n"
             f"Plage: [{p_min:.2f}, {p_max:.2f}] dB", fontsize=12)
    plt.axis('off')
    
    # 8. Carte de probabilit√©s (sous-figure du milieu, si disponible)
    if proba_map is not None:
        plt.subplot(2, n_plots, 2)
        plt.imshow(proba_map, cmap='plasma')
        plt.colorbar(label='Probabilit√© d\'eau', shrink=0.8)
        
        # Tracer le contour correspondant au seuil
        plt.contour(proba_map > threshold, levels=[0.5], colors=['white'], linewidths=2)
        
        prob_stats = f"Min: {proba_map.min():.4f}\nMax: {proba_map.max():.4f}\nMoyenne: {proba_map.mean():.4f}"
        plt.title(f"Probabilit√©s d'inondation\n"
                 f"Seuil: {threshold}\n"
                 f"{prob_stats}", fontsize=12)
        plt.axis('off')
        
        # Histogramme des probabilit√©s (sous-graphique inf√©rieur)
        plt.subplot(2, n_plots, n_plots + 2)
        hist_data = proba_map.flatten()
        plt.hist(hist_data, bins=50, color='skyblue', alpha=0.7, edgecolor='black')
        plt.axvline(x=threshold, color='red', linestyle='--', linewidth=2, label=f'Seuil ({threshold})')
        plt.xlabel('Probabilit√©')
        plt.ylabel('Nombre de pixels')
        plt.title('Distribution des probabilit√©s')
        plt.legend()
        plt.grid(alpha=0.3)
    
    # 9. R√©sultat de segmentation (derni√®re sous-figure)
    plt.subplot(2, n_plots, n_plots)
    
    # 9a. Afficher l'image originale en niveau de gris
    plt.imshow(vv_norm, cmap='gray')
    
    # 9b. Superposer le masque en bleu semi-transparent
    if np.sum(mask) > 0:  # V√©rifier que le masque contient des pixels positifs
        masked = np.ma.masked_where(mask == 0, mask)
        plt.imshow(masked, cmap='cool', alpha=0.7)
        txt_color = 'darkblue'
    else:
        txt_color = 'red'  # Rouge si aucun pixel inond√©
        
    plt.title(f"Segmentation U-Net\n"
             f"Inond√©: {pourcentage_inondation:.2f}%\n"
             f"({nb_pixels_inond√©s:,} pixels)", 
             fontsize=12, color=txt_color, weight='bold')
    plt.axis('off')
    
    # Statistiques d√©taill√©es (derni√®re sous-figure inf√©rieure)
    if proba_map is not None:
        plt.subplot(2, n_plots, 2*n_plots)
    else:
        plt.subplot(2, n_plots, n_plots + 1)
    
    # Tableau de statistiques
    stats_text = f"""STATISTIQUES D√âTAILL√âES:
    
        Image originale:
        ‚Ä¢ Dimensions: {vv.shape[0]} √ó {vv.shape[1]} pixels
        ‚Ä¢ Valeurs SAR: [{vv.min():.2f}, {vv.max():.2f}] dB
        ‚Ä¢ Plage visualisation: [{p_min:.2f}, {p_max:.2f}] dB

        R√©sultats de segmentation:
        ‚Ä¢ Seuil utilis√©: {threshold}
        ‚Ä¢ Pixels inond√©s: {nb_pixels_inond√©s:,} ({pourcentage_inondation:.2f}%)
        ‚Ä¢ Pixels non-inond√©s: {nb_pixels_total - nb_pixels_inond√©s:,} ({100-pourcentage_inondation:.2f}%)
        ‚Ä¢ Total: {nb_pixels_total:,} pixels"""

    if proba_map is not None:
        stats_text += f"""

        Probabilit√©s:
        ‚Ä¢ Min: {proba_map.min():.4f}
        ‚Ä¢ Max: {proba_map.max():.4f}
        ‚Ä¢ Moyenne: {proba_map.mean():.4f}
        ‚Ä¢ √âcart-type: {proba_map.std():.4f}"""

    plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes, 
             fontsize=10, verticalalignment='top', 
             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
    plt.axis('off')
    
    # 10. Finaliser la mise en page
    plt.tight_layout(pad=2.0)
    
    # 11. Sauvegarder l'image avec nom d√©taill√©
    if output_png is None:
        from datetime import datetime
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        base_name = os.path.splitext(os.path.basename(vv_path))[0]
        output_dir = os.path.dirname(vv_path)
        output_png = os.path.join(output_dir, f"segmentation_complete_{base_name}_{timestamp}.png")
    
    plt.savefig(output_png, dpi=300, bbox_inches='tight', facecolor='white', 
               edgecolor='none', pad_inches=0.3)
    print(f"‚úÖ Visualisation compl√®te sauvegard√©e: {output_png}")
    
    # Sauvegarder aussi une version r√©sum√©
    summary_png = output_png.replace('.png', '_resume.png')
    
    # Cr√©er une version r√©sum√©
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 3, 1)
    plt.imshow(vv_norm, cmap='viridis')
    plt.title("Original SAR", fontsize=14)
    plt.axis('off')
    
    if proba_map is not None:
        plt.subplot(1, 3, 2)
        plt.imshow(proba_map, cmap='plasma')
        plt.title("Probabilit√©s", fontsize=14)
        plt.axis('off')
    
    plt.subplot(1, 3, 3)
    plt.imshow(vv_norm, cmap='gray')
    if np.sum(mask) > 0:
        masked = np.ma.masked_where(mask == 0, mask)
        plt.imshow(masked, cmap='cool', alpha=0.7)
    plt.title(f"Segmentation\n{pourcentage_inondation:.1f}% inond√©", fontsize=14)
    plt.axis('off')
    
    plt.tight_layout()
    plt.savefig(summary_png, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"‚úÖ R√©sum√© sauvegard√©: {summary_png}")
    plt.close()
    
    plt.show()
    return output_png


